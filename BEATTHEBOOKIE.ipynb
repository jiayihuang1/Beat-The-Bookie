{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiayihuang1/Beat-The-Bookie/blob/main/BEATTHEBOOKIE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzKLsbxe7YYO"
      },
      "source": [
        "# Beat the Bookies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsD7qRCa7YYP"
      },
      "source": [
        "# Introduction\n",
        "To predict EPL football matches in 2022, we have built a predictive classification model that takes in features such as: ELO ratings, last N games played, distance travelled by away teams, club expenses and net spending. Data provided and additional data collected were used to generate our features. For our classification model, we considered various algorithms, that have all been trained, validated and evaluated to choose the best performing model. In our case, Linear Discriminant Analysis was the best model, producing a training accuracy of 65%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lecpr0sFJ_Ug"
      },
      "source": [
        "\n",
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWXIEhQ2KUqH"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import read_csv\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from numpy import set_printoptions\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score, roc_curve, precision_recall_curve\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import resample\n",
        "from scipy.stats import expon\n",
        "import seaborn as sb\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.feature_selection import mutual_info_classif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twAtyvHMulJ7"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PV3kdHZB7YYR"
      },
      "outputs": [],
      "source": [
        "# changing directory\n",
        "import os\n",
        "\n",
        "os.chdir(\"\\\\Users\\Jia Yi\\Desktop\\Machine Learning\\Group CW\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddxkgdtUJ8-e"
      },
      "outputs": [],
      "source": [
        "#Loading dataframe in Pandas\n",
        "df_epl = pd.read_csv('epl-training2.csv')\n",
        "df_dist = pd.read_csv('dist.csv')\n",
        "df_pred = pd.read_csv('epl-test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCND25RPum9X"
      },
      "source": [
        "# Data Pre-Processing\n",
        "Firstly, we remove empty columns from all of our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_dnicVsvLWP",
        "outputId": "0da7f18d-0ddd-441a-c4a6-76f120f43624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4723 entries, 0 to 4722\n",
            "Data columns (total 38 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Date      4723 non-null   object \n",
            " 1   HomeTeam  4723 non-null   object \n",
            " 2   AwayTeam  4723 non-null   object \n",
            " 3   FTHG      4723 non-null   int64  \n",
            " 4   FTAG      4723 non-null   int64  \n",
            " 5   FTR       4723 non-null   object \n",
            " 6   HTHG      4723 non-null   int64  \n",
            " 7   HTAG      4723 non-null   int64  \n",
            " 8   HTR       4723 non-null   object \n",
            " 9   Referee   4723 non-null   object \n",
            " 10  HS        4723 non-null   int64  \n",
            " 11  AS        4723 non-null   int64  \n",
            " 12  HST       4723 non-null   int64  \n",
            " 13  AST       4723 non-null   int64  \n",
            " 14  HF        4723 non-null   int64  \n",
            " 15  AF        4723 non-null   int64  \n",
            " 16  HC        4723 non-null   int64  \n",
            " 17  AC        4723 non-null   int64  \n",
            " 18  HY        4723 non-null   int64  \n",
            " 19  AY        4723 non-null   int64  \n",
            " 20  HR        4723 non-null   int64  \n",
            " 21  AR        4723 non-null   int64  \n",
            " 22  HPA       4723 non-null   int64  \n",
            " 23  APA       4723 non-null   int64  \n",
            " 24  HPG       4723 non-null   int64  \n",
            " 25  APG       4723 non-null   int64  \n",
            " 26  HCR       4723 non-null   float64\n",
            " 27  ACR       4723 non-null   float64\n",
            " 28  HP        4723 non-null   float64\n",
            " 29  AP        4723 non-null   float64\n",
            " 30  HSZA      4723 non-null   int64  \n",
            " 31  HSZB      4723 non-null   int64  \n",
            " 32  HSZC      4723 non-null   int64  \n",
            " 33  ASZA      4723 non-null   int64  \n",
            " 34  ASZB      4723 non-null   int64  \n",
            " 35  ASZC      4723 non-null   int64  \n",
            " 36  FTHG_P    4723 non-null   int64  \n",
            " 37  FTAG_P    4723 non-null   int64  \n",
            "dtypes: float64(4), int64(28), object(6)\n",
            "memory usage: 1.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df_epl = df_epl.dropna(axis=1) # drop NaN columns\n",
        "df_epl.info() # checking info of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdyqZcTt7YYS"
      },
      "source": [
        "We have verified that there is nothing wrong with the data. Hence, we move on to other parts of pre-processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4Sdq7wz7YYS"
      },
      "source": [
        "To prepare for feature engineering, we extract the list of clubnames and prepare functions to convert categorical values to integer values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EADFyRsNviCs"
      },
      "outputs": [],
      "source": [
        "# Creating row of clubnames\n",
        "clubnames = []\n",
        "with open('epl-training2.csv', newline = '') as csvfile:\n",
        "  reader = csv.reader(csvfile, delimiter=',')\n",
        "  for row in reader:\n",
        "      clubnames.append(row[1])\n",
        "\n",
        "clubnames = list(dict.fromkeys(clubnames))\n",
        "clubnames.pop(0)\n",
        "\n",
        "#Convert FTR to 0,1,2\n",
        "def conv_HAD_to_012(df_in):\n",
        "    df = df_in.copy() #create a new df so as to not modify the original\n",
        "    # HomeWin = 0, Draw = 1, AwayWin = 2\n",
        "    #\"FTR\" column is column number 8 (or 9)\n",
        "    for n in range(df.shape[0]):\n",
        "        if df.iloc[n,5] == \"H\":\n",
        "            df.iloc[n,5]= \"0\"\n",
        "        elif df.iloc[n,5]== \"D\":\n",
        "            df.iloc[n,5]= \"1\"\n",
        "        else:\n",
        "            df.iloc[n,5]= \"2\"\n",
        "    return df\n",
        "\n",
        "# function to convert clubnames to integers\n",
        "def conv_clubname_to_int(df, clubnames):\n",
        "    #club names converted to a number in order of first appearance in dataset\n",
        "    #Arsenal = 0, Bolton = 2, Everton = 3... Leeds = 37 (last)\n",
        "    df2 = df.copy()\n",
        "    for n in range(df2.shape[0]):\n",
        "        for name in clubnames:\n",
        "            #Change Home Team Name\n",
        "            if df2.iloc[n,1] == name:\n",
        "                df2.iloc[n,1] = clubnames.index(name)\n",
        "            #Change Away Team Name\n",
        "            if df2.iloc[n,2] == name:\n",
        "                df2.iloc[n,2] = clubnames.index(name)\n",
        "\n",
        "    return df2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XHhsN1-7YYS"
      },
      "source": [
        "Here we aim to prepare dataframes containing both the training and testing data to be used to generate features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAl2y0327YYT",
        "outputId": "7bb8707f-2121-47f7-c8a6-a0fc7d660f06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>AwayTeam</th>\n",
              "      <th>FTR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Training</th>\n",
              "      <th>0</th>\n",
              "      <td>15-08-09</td>\n",
              "      <td>Aston Villa</td>\n",
              "      <td>Wigan</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15-08-09</td>\n",
              "      <td>Blackburn</td>\n",
              "      <td>Man City</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15-08-09</td>\n",
              "      <td>Bolton</td>\n",
              "      <td>Sunderland</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15-08-09</td>\n",
              "      <td>Chelsea</td>\n",
              "      <td>Hull</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15-08-09</td>\n",
              "      <td>Everton</td>\n",
              "      <td>Arsenal</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Testing</th>\n",
              "      <th>5</th>\n",
              "      <td>15-01-22</td>\n",
              "      <td>Liverpool</td>\n",
              "      <td>Brentford</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>15-01-22</td>\n",
              "      <td>Tottenham</td>\n",
              "      <td>Arsenal</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>15-01-22</td>\n",
              "      <td>Man City</td>\n",
              "      <td>Chelsea</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>15-01-22</td>\n",
              "      <td>Newcastle</td>\n",
              "      <td>Watford</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>15-01-22</td>\n",
              "      <td>Burnley</td>\n",
              "      <td>Leicester</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4733 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Date     HomeTeam    AwayTeam  FTR\n",
              "Training 0  15-08-09  Aston Villa       Wigan    A\n",
              "         1  15-08-09    Blackburn    Man City    A\n",
              "         2  15-08-09       Bolton  Sunderland    A\n",
              "         3  15-08-09      Chelsea        Hull    H\n",
              "         4  15-08-09      Everton     Arsenal    A\n",
              "...              ...          ...         ...  ...\n",
              "Testing  5  15-01-22    Liverpool   Brentford  NaN\n",
              "         6  15-01-22    Tottenham     Arsenal  NaN\n",
              "         7  15-01-22     Man City     Chelsea  NaN\n",
              "         8  15-01-22    Newcastle     Watford  NaN\n",
              "         9  15-01-22      Burnley   Leicester  NaN\n",
              "\n",
              "[4733 rows x 4 columns]"
            ]
          },
          "execution_count": 310,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_pred2 = df_epl[['Date','HomeTeam','AwayTeam','FTR']].copy()\n",
        "frame = [df_pred2,df_pred]\n",
        "df_pred3 = pd.concat(frame,keys=[\"Training\",\"Testing\"])\n",
        "df_pred3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6jGdeAOJBaw"
      },
      "source": [
        "# Feature Engineering\n",
        "In this section, we generate all features that we believe have a strong correlation with match outcomes.\n",
        "Features:\n",
        "- ELO Rating - Represents relative team strength based on performance of past matches\n",
        "- Last N Points - Represents most recent performance of teams\n",
        "- Spending - Represents expenses and net spending at the start of each season\n",
        "- Fatigue - Represents physical exhaustion of teams based on how close together their matches are\n",
        "- Distance travelled by away team"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sej_OnDOjNlT"
      },
      "source": [
        "## ELO Rating\n",
        "Steps:\n",
        "1. Prepare features for regression models  \n",
        "2. Building shot and non-shot based regression models\n",
        "3. Use models to predict expected match values\n",
        "4. Calculate ELO rating based on expected match values\n",
        "5. Update ELO rating for each team"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O4OUyFK7YYT"
      },
      "source": [
        "Preparing dataset with features that are relavent and tranforming them into an appropriate format to feed into our regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAkH6LaNJLT-"
      },
      "outputs": [],
      "source": [
        "# separating dataset for shot and non_shot based\n",
        "Hshots = df_epl[['HSZA','HSZB','HSZC','HST','FTHG_P']]\n",
        "Ashots = df_epl[['ASZA','ASZB','ASZC','AST','FTAG_P']]\n",
        "Hnonshot = df_epl[['HP','HC','HCR','FTHG_P']]\n",
        "Anonshot = df_epl[['AP','AC','ACR','FTAG_P']]\n",
        "\n",
        "# changing home and away columns to the same name so that they can be combined\n",
        "Hshots = Hshots.rename(columns={'HSZA':'SZA','HSZB':'SZB','HSZC':'SZC','HST':'SOT',\n",
        "                                'FTHG_P':'FTG_P'})\n",
        "Ashots = Ashots.rename(columns={'ASZA':'SZA','ASZB':'SZB','ASZC':'SZC','AST':'SOT',\n",
        "                                'FTAG_P':'FTG_P'})\n",
        "Hnonshot = Hnonshot.rename(columns={'HP':'P','HC':'C','HCR':'CR','FTHG_P':'FTG_P'})\n",
        "Anonshot = Anonshot.rename(columns={'AP':'P','AC':'C','ACR':'CR','FTAG_P':'FTG_P'})\n",
        "\n",
        "# combining both home and away data for regression model\n",
        "frame1 = [Hshots, Ashots]\n",
        "shots = pd.concat(frame1,keys=[\"Home\",\"Away\"])\n",
        "frame2 = [Hnonshot, Anonshot]\n",
        "nonshot = pd.concat(frame2,keys=[\"Home\",\"Away\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL-0fcJjNTRv"
      },
      "outputs": [],
      "source": [
        "# separating input and output variables for all datasets\n",
        "x_shots,y_shots = shots.drop('FTG_P',axis=1),shots['FTG_P'].copy()\n",
        "x_nonshot,y_nonshot = nonshot.drop('FTG_P',axis=1),nonshot['FTG_P'].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6YMJPBLj9F3"
      },
      "source": [
        "### Model Training, Validation and Evaluation for regression models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kUGAMAdkLsJ"
      },
      "source": [
        "#### Scoring method\n",
        "We decided to use mean squared error as our evaluation metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abkW3rEVbOsU"
      },
      "outputs": [],
      "source": [
        "scorer = make_scorer(mean_squared_error, greater_is_better=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kh826xgkRUU"
      },
      "source": [
        "#### Shot based expected match value model\n",
        "Now we begin to build our model by performing these steps:\n",
        "1. Train several models using different algorithms\n",
        "2. Validate models using K-fold cross validation\n",
        "3. Tune hyperparameters of relevant algorithms\n",
        "4. Evaluate and select the best performing model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpm_Ovqn7YYU"
      },
      "source": [
        "Here we split training data into training and validation sets for performance evaluation. We also scale our input features before feeding into our models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIw8Vl65kkXF"
      },
      "outputs": [],
      "source": [
        "# splitting training and testing data\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_shots, y_shots, test_size = 0.2, random_state=42)\n",
        "\n",
        "# standardise\n",
        "scaler = StandardScaler()\n",
        "x_train_scale = scaler.fit_transform(x_train)\n",
        "x_test_scale = scaler.transform(x_test)\n",
        "x_shots_scale = scaler.transform(x_shots)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyXr7VK-kYBt"
      },
      "source": [
        "###### Multivariate Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P07GfG9bQmT",
        "outputId": "fa89085a-778a-4b6c-ed22-64988836c368"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE of linear regressor on training data =  1.0701079427759976\n",
            "MSE of linear regressor on testing data =  1.1125681615645435\n",
            "difference in MSE of linear regressor =  0.04246021878854589\n"
          ]
        }
      ],
      "source": [
        "# fit\n",
        "lr_shots = LinearRegression()\n",
        "lr_shots.fit(x_train_scale,y_train)\n",
        "\n",
        "# predict\n",
        "ytrain_lr_shots = lr_shots.predict(x_train_scale)\n",
        "ytest_lr_shots = lr_shots.predict(x_test_scale)\n",
        "\n",
        "# evaluate\n",
        "mse_lr_shots_train = mean_squared_error(ytrain_lr_shots,y_train)\n",
        "mse_lr_shots_test = mean_squared_error(ytest_lr_shots,y_test)\n",
        "genloss_lr_shots = mse_lr_shots_test - mse_lr_shots_train\n",
        "\n",
        "print(\"MSE of linear regressor on training data = \",mse_lr_shots_train)\n",
        "print(\"MSE of linear regressor on testing data = \",mse_lr_shots_test)\n",
        "print(\"difference in MSE of linear regressor = \",genloss_lr_shots)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se4K-NgX7YYU",
        "outputId": "1afa64ce-4680-487f-adf7-85932b23da2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nested Cross Validation mean test score: -1.0724026446924162\n"
          ]
        }
      ],
      "source": [
        "# perform cross validation\n",
        "shots_lr_cv = cross_val_score(lr_shots, X=x_train_scale, y=y_train, cv=5, scoring=scorer)\n",
        "shots_lr_err = shots_lr_cv.mean()\n",
        "print('Nested Cross Validation mean test score:',shots_lr_err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lIWynNu7YYU"
      },
      "source": [
        "Difference between test score calculated with cross validation and score calculated with our validation set is small. Therefore, we choose to use score calculated with validation set so it can be compared to our training error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTTS8lfPN7mR",
        "outputId": "42631950-00ea-4f72-f244-599d3c79eecd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SZA    0.174233\n",
              "SZB    0.145753\n",
              "SZC   -0.188423\n",
              "SOT    0.543063\n",
              "dtype: float64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checking parameters for shot based expected match value\n",
        "param_shot = pd.Series(lr_shots.coef_, index=x_shots.columns)\n",
        "np.random.seed(1)\n",
        "err_shot = np.std([lr_shots.fit(*resample(x_shots,y_shots)).coef_ for i in range(1000)],0)\n",
        "param_shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VD5RNGs7YYU"
      },
      "source": [
        "These values show the coefficients for our input variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shXByHuekvSA"
      },
      "source": [
        "##### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gVDZJHVcTcr",
        "outputId": "585387f8-2a1b-471d-b2c4-ae53770d40f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   57.2s\n",
            "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  9.2min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best score for RF is: -1.0870323165571385\n",
            "The best parameters for RF are: RandomForestRegressor(max_depth=100, max_features=2, min_samples_leaf=5,\n",
            "                      min_samples_split=12, n_estimators=200)\n",
            "MSE of random forest regressor on training data =  0.8585116343187885\n",
            "MSE of random forest regressor on testing data =  1.1246989638437914\n",
            "difference in MSE of random forest regressor =  0.2661873295250029\n"
          ]
        }
      ],
      "source": [
        "# Create the parameter grid\n",
        "RF_paramgrid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [80, 90, 100, 110],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000]\n",
        "}\n",
        "# Create a base model\n",
        "rf = RandomForestRegressor()\n",
        "# Instantiate the grid search model\n",
        "grid_rf = GridSearchCV(estimator = rf, param_grid = RF_paramgrid,\n",
        "                          cv = 5, n_jobs = -1, verbose = 2, scoring=scorer)\n",
        "# Fit the grid search model\n",
        "grid_rf.fit(x_train_scale, y_train)\n",
        "\n",
        "# check values of hyperparameters and best test score from cross validation\n",
        "print('The best score for RF is:',grid_rf.best_score_)\n",
        "print('The best parameters for RF are:',grid_rf.best_estimator_)\n",
        "\n",
        "# build the final model with the optimum hyperparameters\n",
        "rfr_model = (grid_rf.best_estimator_)\n",
        "\n",
        "# fit the final model\n",
        "RF_fit = rfr_model.fit(x_train_scale, y_train)\n",
        "\n",
        "# predict\n",
        "ytrain_rf_shots = RF_fit.predict(x_train_scale)\n",
        "ytest_rf_shots = RF_fit.predict(x_test_scale)\n",
        "\n",
        "# evaluate\n",
        "mse_rf_shots_train = mean_squared_error(ytrain_rf_shots,y_train)\n",
        "mse_rf_shots_test = mean_squared_error(ytest_rf_shots,y_test)\n",
        "genloss_rf_shots = mse_rf_shots_test - mse_rf_shots_train\n",
        "\n",
        "print(\"MSE of random forest regressor on training data = \",mse_rf_shots_train)\n",
        "print(\"MSE of random forest regressor on testing data = \",mse_rf_shots_test)\n",
        "print(\"difference in MSE of random forest regressor = \",genloss_rf_shots)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93TkaiKNk9to"
      },
      "source": [
        "##### Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q38gq_Jucqk6",
        "outputId": "9f011838-2047-4b70-96d5-468193cd7bc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] ......... C=0.1, gamma=1, kernel=rbf, score=-1.077, total=   1.2s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] ......... C=0.1, gamma=1, kernel=rbf, score=-1.098, total=   1.2s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.3s remaining:    0.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] ......... C=0.1, gamma=1, kernel=rbf, score=-1.076, total=   1.1s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] ......... C=0.1, gamma=1, kernel=rbf, score=-1.221, total=   1.1s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] ......... C=0.1, gamma=1, kernel=rbf, score=-1.193, total=   1.1s\n",
            "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=0.1, gamma=1, kernel=linear, score=-1.060, total=   0.8s\n",
            "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=0.1, gamma=1, kernel=linear, score=-1.057, total=   0.8s\n",
            "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=0.1, gamma=1, kernel=linear, score=-1.047, total=   0.8s\n",
            "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=0.1, gamma=1, kernel=linear, score=-1.170, total=   0.8s\n",
            "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=0.1, gamma=1, kernel=linear, score=-1.090, total=   0.8s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=0.1, gamma=0.1, kernel=rbf, score=-1.040, total=   1.2s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=0.1, gamma=0.1, kernel=rbf, score=-1.053, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=0.1, gamma=0.1, kernel=rbf, score=-1.023, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=0.1, gamma=0.1, kernel=rbf, score=-1.137, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=0.1, gamma=0.1, kernel=rbf, score=-1.111, total=   1.2s\n",
            "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=0.1, gamma=0.1, kernel=linear, score=-1.060, total=   0.9s\n",
            "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=0.1, gamma=0.1, kernel=linear, score=-1.057, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=0.1, gamma=0.1, kernel=linear, score=-1.047, total=   0.8s\n",
            "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=0.1, gamma=0.1, kernel=linear, score=-1.170, total=   0.8s\n",
            "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=0.1, gamma=0.1, kernel=linear, score=-1.090, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=0.1, gamma=0.01, kernel=rbf, score=-1.047, total=   1.8s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=0.1, gamma=0.01, kernel=rbf, score=-1.054, total=   2.3s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=0.1, gamma=0.01, kernel=rbf, score=-1.042, total=   2.2s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=0.1, gamma=0.01, kernel=rbf, score=-1.158, total=   1.6s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=0.1, gamma=0.01, kernel=rbf, score=-1.108, total=   1.3s\n",
            "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=0.1, gamma=0.01, kernel=linear, score=-1.060, total=   0.9s\n",
            "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=0.1, gamma=0.01, kernel=linear, score=-1.057, total=   0.9s\n",
            "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=0.1, gamma=0.01, kernel=linear, score=-1.047, total=   0.7s\n",
            "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=0.1, gamma=0.01, kernel=linear, score=-1.170, total=   0.7s\n",
            "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=0.1, gamma=0.01, kernel=linear, score=-1.090, total=   0.9s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=0.1, gamma=0.001, kernel=rbf, score=-1.151, total=   1.2s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=0.1, gamma=0.001, kernel=rbf, score=-1.183, total=   1.2s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=0.1, gamma=0.001, kernel=rbf, score=-1.182, total=   1.2s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=0.1, gamma=0.001, kernel=rbf, score=-1.330, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=0.1, gamma=0.001, kernel=rbf, score=-1.244, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=0.1, gamma=0.001, kernel=linear, score=-1.060, total=   0.9s\n",
            "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=0.1, gamma=0.001, kernel=linear, score=-1.057, total=   0.8s\n",
            "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=0.1, gamma=0.001, kernel=linear, score=-1.047, total=   0.8s\n",
            "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=0.1, gamma=0.001, kernel=linear, score=-1.170, total=   0.8s\n",
            "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=0.1, gamma=0.001, kernel=linear, score=-1.090, total=   0.9s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=0.1, gamma=0.0001, kernel=rbf, score=-1.369, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=0.1, gamma=0.0001, kernel=rbf, score=-1.424, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=0.1, gamma=0.0001, kernel=rbf, score=-1.424, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=0.1, gamma=0.0001, kernel=rbf, score=-1.597, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=0.1, gamma=0.0001, kernel=rbf, score=-1.516, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=0.1, gamma=0.0001, kernel=linear, score=-1.060, total=   0.8s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=0.1, gamma=0.0001, kernel=linear, score=-1.057, total=   0.9s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=0.1, gamma=0.0001, kernel=linear, score=-1.047, total=   0.8s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=0.1, gamma=0.0001, kernel=linear, score=-1.170, total=   0.8s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=0.1, gamma=0.0001, kernel=linear, score=-1.090, total=   0.7s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ........... C=1, gamma=1, kernel=rbf, score=-1.100, total=   1.3s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ........... C=1, gamma=1, kernel=rbf, score=-1.112, total=   1.3s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ........... C=1, gamma=1, kernel=rbf, score=-1.072, total=   1.2s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ........... C=1, gamma=1, kernel=rbf, score=-1.203, total=   1.4s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ........... C=1, gamma=1, kernel=rbf, score=-1.164, total=   1.2s\n",
            "[CV] C=1, gamma=1, kernel=linear .....................................\n",
            "[CV] ........ C=1, gamma=1, kernel=linear, score=-1.060, total=   1.4s\n",
            "[CV] C=1, gamma=1, kernel=linear .....................................\n",
            "[CV] ........ C=1, gamma=1, kernel=linear, score=-1.057, total=   1.2s\n",
            "[CV] C=1, gamma=1, kernel=linear .....................................\n",
            "[CV] ........ C=1, gamma=1, kernel=linear, score=-1.047, total=   1.4s\n",
            "[CV] C=1, gamma=1, kernel=linear .....................................\n",
            "[CV] ........ C=1, gamma=1, kernel=linear, score=-1.170, total=   1.3s\n",
            "[CV] C=1, gamma=1, kernel=linear .....................................\n",
            "[CV] ........ C=1, gamma=1, kernel=linear, score=-1.089, total=   1.4s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] ......... C=1, gamma=0.1, kernel=rbf, score=-1.043, total=   1.3s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] ......... C=1, gamma=0.1, kernel=rbf, score=-1.048, total=   1.2s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] ......... C=1, gamma=0.1, kernel=rbf, score=-1.020, total=   1.2s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] ......... C=1, gamma=0.1, kernel=rbf, score=-1.135, total=   1.3s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] ......... C=1, gamma=0.1, kernel=rbf, score=-1.078, total=   1.2s\n",
            "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
            "[CV] ...... C=1, gamma=0.1, kernel=linear, score=-1.060, total=   1.3s\n",
            "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
            "[CV] ...... C=1, gamma=0.1, kernel=linear, score=-1.057, total=   1.3s\n",
            "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
            "[CV] ...... C=1, gamma=0.1, kernel=linear, score=-1.047, total=   1.6s\n",
            "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
            "[CV] ...... C=1, gamma=0.1, kernel=linear, score=-1.170, total=   1.3s\n",
            "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
            "[CV] ...... C=1, gamma=0.1, kernel=linear, score=-1.089, total=   1.5s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ........ C=1, gamma=0.01, kernel=rbf, score=-1.035, total=   1.5s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ........ C=1, gamma=0.01, kernel=rbf, score=-1.040, total=   1.2s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ........ C=1, gamma=0.01, kernel=rbf, score=-1.019, total=   1.2s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ........ C=1, gamma=0.01, kernel=rbf, score=-1.138, total=   1.2s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ........ C=1, gamma=0.01, kernel=rbf, score=-1.100, total=   1.3s\n",
            "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
            "[CV] ..... C=1, gamma=0.01, kernel=linear, score=-1.060, total=   1.7s\n",
            "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
            "[CV] ..... C=1, gamma=0.01, kernel=linear, score=-1.057, total=   1.4s\n",
            "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
            "[CV] ..... C=1, gamma=0.01, kernel=linear, score=-1.047, total=   1.6s\n",
            "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
            "[CV] ..... C=1, gamma=0.01, kernel=linear, score=-1.170, total=   1.3s\n",
            "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
            "[CV] ..... C=1, gamma=0.01, kernel=linear, score=-1.089, total=   1.4s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ....... C=1, gamma=0.001, kernel=rbf, score=-1.055, total=   1.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ....... C=1, gamma=0.001, kernel=rbf, score=-1.058, total=   1.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ....... C=1, gamma=0.001, kernel=rbf, score=-1.048, total=   1.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ....... C=1, gamma=0.001, kernel=rbf, score=-1.169, total=   1.2s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ....... C=1, gamma=0.001, kernel=rbf, score=-1.098, total=   1.2s\n",
            "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
            "[CV] .... C=1, gamma=0.001, kernel=linear, score=-1.060, total=   1.4s\n",
            "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
            "[CV] .... C=1, gamma=0.001, kernel=linear, score=-1.057, total=   1.3s\n",
            "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
            "[CV] .... C=1, gamma=0.001, kernel=linear, score=-1.047, total=   1.4s\n",
            "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
            "[CV] .... C=1, gamma=0.001, kernel=linear, score=-1.170, total=   1.3s\n",
            "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
            "[CV] .... C=1, gamma=0.001, kernel=linear, score=-1.089, total=   1.4s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ...... C=1, gamma=0.0001, kernel=rbf, score=-1.151, total=   1.1s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ...... C=1, gamma=0.0001, kernel=rbf, score=-1.183, total=   1.1s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ...... C=1, gamma=0.0001, kernel=rbf, score=-1.180, total=   1.2s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ...... C=1, gamma=0.0001, kernel=rbf, score=-1.330, total=   1.2s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ...... C=1, gamma=0.0001, kernel=rbf, score=-1.243, total=   1.2s\n",
            "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
            "[CV] ... C=1, gamma=0.0001, kernel=linear, score=-1.060, total=   1.6s\n",
            "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
            "[CV] ... C=1, gamma=0.0001, kernel=linear, score=-1.057, total=   1.2s\n",
            "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
            "[CV] ... C=1, gamma=0.0001, kernel=linear, score=-1.047, total=   1.6s\n",
            "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
            "[CV] ... C=1, gamma=0.0001, kernel=linear, score=-1.170, total=   1.7s\n",
            "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
            "[CV] ... C=1, gamma=0.0001, kernel=linear, score=-1.089, total=   1.8s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] .......... C=10, gamma=1, kernel=rbf, score=-1.204, total=   3.4s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] .......... C=10, gamma=1, kernel=rbf, score=-1.197, total=   3.0s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] .......... C=10, gamma=1, kernel=rbf, score=-1.212, total=   2.8s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] .......... C=10, gamma=1, kernel=rbf, score=-1.347, total=   2.9s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] .......... C=10, gamma=1, kernel=rbf, score=-1.261, total=   3.1s\n",
            "[CV] C=10, gamma=1, kernel=linear ....................................\n",
            "[CV] ....... C=10, gamma=1, kernel=linear, score=-1.060, total=   6.9s\n",
            "[CV] C=10, gamma=1, kernel=linear ....................................\n",
            "[CV] ....... C=10, gamma=1, kernel=linear, score=-1.057, total=   5.2s\n",
            "[CV] C=10, gamma=1, kernel=linear ....................................\n",
            "[CV] ....... C=10, gamma=1, kernel=linear, score=-1.047, total=   5.8s\n",
            "[CV] C=10, gamma=1, kernel=linear ....................................\n",
            "[CV] ....... C=10, gamma=1, kernel=linear, score=-1.170, total=   5.1s\n",
            "[CV] C=10, gamma=1, kernel=linear ....................................\n",
            "[CV] ....... C=10, gamma=1, kernel=linear, score=-1.089, total=   5.1s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ........ C=10, gamma=0.1, kernel=rbf, score=-1.061, total=   1.5s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ........ C=10, gamma=0.1, kernel=rbf, score=-1.057, total=   1.5s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ........ C=10, gamma=0.1, kernel=rbf, score=-1.045, total=   1.5s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ........ C=10, gamma=0.1, kernel=rbf, score=-1.183, total=   1.6s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ........ C=10, gamma=0.1, kernel=rbf, score=-1.090, total=   1.6s\n",
            "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
            "[CV] ..... C=10, gamma=0.1, kernel=linear, score=-1.060, total=   5.7s\n",
            "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
            "[CV] ..... C=10, gamma=0.1, kernel=linear, score=-1.057, total=   5.6s\n",
            "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
            "[CV] ..... C=10, gamma=0.1, kernel=linear, score=-1.047, total=   5.4s\n",
            "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
            "[CV] ..... C=10, gamma=0.1, kernel=linear, score=-1.170, total=   5.2s\n",
            "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
            "[CV] ..... C=10, gamma=0.1, kernel=linear, score=-1.089, total=   5.3s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ....... C=10, gamma=0.01, kernel=rbf, score=-1.030, total=   1.2s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ....... C=10, gamma=0.01, kernel=rbf, score=-1.035, total=   1.2s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ....... C=10, gamma=0.01, kernel=rbf, score=-1.009, total=   1.2s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ....... C=10, gamma=0.01, kernel=rbf, score=-1.130, total=   1.2s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ....... C=10, gamma=0.01, kernel=rbf, score=-1.085, total=   1.2s\n",
            "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
            "[CV] .... C=10, gamma=0.01, kernel=linear, score=-1.060, total=   5.4s\n",
            "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
            "[CV] .... C=10, gamma=0.01, kernel=linear, score=-1.057, total=   5.1s\n",
            "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
            "[CV] .... C=10, gamma=0.01, kernel=linear, score=-1.047, total=   5.6s\n",
            "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
            "[CV] .... C=10, gamma=0.01, kernel=linear, score=-1.170, total=   4.8s\n",
            "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
            "[CV] .... C=10, gamma=0.01, kernel=linear, score=-1.089, total=   5.4s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ...... C=10, gamma=0.001, kernel=rbf, score=-1.046, total=   1.1s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ...... C=10, gamma=0.001, kernel=rbf, score=-1.047, total=   1.1s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ...... C=10, gamma=0.001, kernel=rbf, score=-1.033, total=   1.2s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ...... C=10, gamma=0.001, kernel=rbf, score=-1.152, total=   1.2s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ...... C=10, gamma=0.001, kernel=rbf, score=-1.095, total=   1.2s\n",
            "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
            "[CV] ... C=10, gamma=0.001, kernel=linear, score=-1.060, total=   5.4s\n",
            "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
            "[CV] ... C=10, gamma=0.001, kernel=linear, score=-1.057, total=   5.4s\n",
            "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
            "[CV] ... C=10, gamma=0.001, kernel=linear, score=-1.047, total=   5.4s\n",
            "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
            "[CV] ... C=10, gamma=0.001, kernel=linear, score=-1.170, total=   4.6s\n",
            "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
            "[CV] ... C=10, gamma=0.001, kernel=linear, score=-1.089, total=   5.1s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ..... C=10, gamma=0.0001, kernel=rbf, score=-1.058, total=   1.1s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ..... C=10, gamma=0.0001, kernel=rbf, score=-1.060, total=   1.1s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ..... C=10, gamma=0.0001, kernel=rbf, score=-1.052, total=   1.1s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ..... C=10, gamma=0.0001, kernel=rbf, score=-1.173, total=   1.2s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ..... C=10, gamma=0.0001, kernel=rbf, score=-1.095, total=   1.2s\n",
            "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
            "[CV] .. C=10, gamma=0.0001, kernel=linear, score=-1.060, total=   5.3s\n",
            "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
            "[CV] .. C=10, gamma=0.0001, kernel=linear, score=-1.057, total=   5.0s\n",
            "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
            "[CV] .. C=10, gamma=0.0001, kernel=linear, score=-1.047, total=   5.4s\n",
            "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
            "[CV] .. C=10, gamma=0.0001, kernel=linear, score=-1.170, total=   5.8s\n",
            "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
            "[CV] .. C=10, gamma=0.0001, kernel=linear, score=-1.089, total=   5.1s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] ......... C=100, gamma=1, kernel=rbf, score=-1.446, total=  16.6s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] ......... C=100, gamma=1, kernel=rbf, score=-1.510, total=  17.2s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] ......... C=100, gamma=1, kernel=rbf, score=-1.490, total=  16.4s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] ......... C=100, gamma=1, kernel=rbf, score=-1.693, total=  24.0s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] ......... C=100, gamma=1, kernel=rbf, score=-1.459, total=  18.2s\n",
            "[CV] C=100, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=100, gamma=1, kernel=linear, score=-1.060, total=  32.2s\n",
            "[CV] C=100, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=100, gamma=1, kernel=linear, score=-1.057, total=  29.5s\n",
            "[CV] C=100, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=100, gamma=1, kernel=linear, score=-1.047, total=  37.3s\n",
            "[CV] C=100, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=100, gamma=1, kernel=linear, score=-1.170, total=  33.2s\n",
            "[CV] C=100, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=100, gamma=1, kernel=linear, score=-1.089, total=  34.1s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=100, gamma=0.1, kernel=rbf, score=-1.106, total=   3.8s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=100, gamma=0.1, kernel=rbf, score=-1.084, total=   3.6s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=100, gamma=0.1, kernel=rbf, score=-1.083, total=   3.8s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=100, gamma=0.1, kernel=rbf, score=-1.235, total=   3.8s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=100, gamma=0.1, kernel=rbf, score=-1.159, total=   3.6s\n",
            "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=100, gamma=0.1, kernel=linear, score=-1.060, total=  33.9s\n",
            "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=100, gamma=0.1, kernel=linear, score=-1.057, total=  31.5s\n",
            "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=100, gamma=0.1, kernel=linear, score=-1.047, total=  36.2s\n",
            "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=100, gamma=0.1, kernel=linear, score=-1.170, total=  35.4s\n",
            "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=100, gamma=0.1, kernel=linear, score=-1.089, total=  32.8s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=100, gamma=0.01, kernel=rbf, score=-1.031, total=   1.6s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=100, gamma=0.01, kernel=rbf, score=-1.040, total=   1.8s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=100, gamma=0.01, kernel=rbf, score=-1.013, total=   2.1s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=100, gamma=0.01, kernel=rbf, score=-1.138, total=   2.0s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=100, gamma=0.01, kernel=rbf, score=-1.077, total=   1.7s\n",
            "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=100, gamma=0.01, kernel=linear, score=-1.060, total=  31.6s\n",
            "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=100, gamma=0.01, kernel=linear, score=-1.057, total=  31.3s\n",
            "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=100, gamma=0.01, kernel=linear, score=-1.047, total=  35.7s\n",
            "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=100, gamma=0.01, kernel=linear, score=-1.170, total=  35.7s\n",
            "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=100, gamma=0.01, kernel=linear, score=-1.089, total=  32.1s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=100, gamma=0.001, kernel=rbf, score=-1.034, total=   1.7s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=100, gamma=0.001, kernel=rbf, score=-1.036, total=   1.2s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=100, gamma=0.001, kernel=rbf, score=-1.016, total=   1.4s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=100, gamma=0.001, kernel=rbf, score=-1.139, total=   1.2s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=100, gamma=0.001, kernel=rbf, score=-1.093, total=   1.2s\n",
            "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=100, gamma=0.001, kernel=linear, score=-1.060, total=  31.2s\n",
            "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=100, gamma=0.001, kernel=linear, score=-1.057, total=  28.5s\n",
            "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=100, gamma=0.001, kernel=linear, score=-1.047, total=  32.0s\n",
            "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=100, gamma=0.001, kernel=linear, score=-1.170, total=  31.0s\n",
            "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=100, gamma=0.001, kernel=linear, score=-1.089, total=  31.3s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=100, gamma=0.0001, kernel=rbf, score=-1.056, total=   1.2s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=100, gamma=0.0001, kernel=rbf, score=-1.054, total=   1.1s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=100, gamma=0.0001, kernel=rbf, score=-1.044, total=   1.2s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=100, gamma=0.0001, kernel=rbf, score=-1.166, total=   1.2s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=100, gamma=0.0001, kernel=rbf, score=-1.089, total=   1.1s\n",
            "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=100, gamma=0.0001, kernel=linear, score=-1.060, total=  30.5s\n",
            "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=100, gamma=0.0001, kernel=linear, score=-1.057, total=  29.0s\n",
            "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=100, gamma=0.0001, kernel=linear, score=-1.047, total=  31.9s\n",
            "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=100, gamma=0.0001, kernel=linear, score=-1.170, total=  31.5s\n",
            "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=100, gamma=0.0001, kernel=linear, score=-1.089, total=  31.3s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ........ C=1000, gamma=1, kernel=rbf, score=-2.314, total= 3.4min\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ........ C=1000, gamma=1, kernel=rbf, score=-2.617, total= 3.3min\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ........ C=1000, gamma=1, kernel=rbf, score=-2.399, total= 3.1min\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ........ C=1000, gamma=1, kernel=rbf, score=-2.805, total= 3.3min\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ........ C=1000, gamma=1, kernel=rbf, score=-2.200, total= 2.8min\n",
            "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
            "[CV] ..... C=1000, gamma=1, kernel=linear, score=-1.060, total= 4.3min\n",
            "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
            "[CV] ..... C=1000, gamma=1, kernel=linear, score=-1.057, total= 4.1min\n",
            "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
            "[CV] ..... C=1000, gamma=1, kernel=linear, score=-1.047, total= 4.3min\n",
            "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
            "[CV] ..... C=1000, gamma=1, kernel=linear, score=-1.170, total= 4.2min\n",
            "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
            "[CV] ..... C=1000, gamma=1, kernel=linear, score=-1.090, total= 4.6min\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ...... C=1000, gamma=0.1, kernel=rbf, score=-1.199, total=  25.9s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ...... C=1000, gamma=0.1, kernel=rbf, score=-1.147, total=  22.2s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ...... C=1000, gamma=0.1, kernel=rbf, score=-1.255, total=  22.8s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ...... C=1000, gamma=0.1, kernel=rbf, score=-1.327, total=  25.9s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ...... C=1000, gamma=0.1, kernel=rbf, score=-1.256, total=  26.8s\n",
            "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
            "[CV] ... C=1000, gamma=0.1, kernel=linear, score=-1.060, total= 4.5min\n",
            "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
            "[CV] ... C=1000, gamma=0.1, kernel=linear, score=-1.057, total= 4.7min\n",
            "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
            "[CV] ... C=1000, gamma=0.1, kernel=linear, score=-1.047, total= 4.7min\n",
            "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
            "[CV] ... C=1000, gamma=0.1, kernel=linear, score=-1.170, total= 4.5min\n",
            "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
            "[CV] ... C=1000, gamma=0.1, kernel=linear, score=-1.090, total= 4.3min\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ..... C=1000, gamma=0.01, kernel=rbf, score=-1.036, total=   4.4s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ..... C=1000, gamma=0.01, kernel=rbf, score=-1.047, total=   4.4s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ..... C=1000, gamma=0.01, kernel=rbf, score=-1.023, total=   4.4s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ..... C=1000, gamma=0.01, kernel=rbf, score=-1.170, total=   4.1s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ..... C=1000, gamma=0.01, kernel=rbf, score=-1.095, total=   4.4s\n",
            "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
            "[CV] .. C=1000, gamma=0.01, kernel=linear, score=-1.060, total= 4.4min\n",
            "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
            "[CV] .. C=1000, gamma=0.01, kernel=linear, score=-1.057, total= 4.4min\n",
            "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
            "[CV] .. C=1000, gamma=0.01, kernel=linear, score=-1.047, total= 4.7min\n",
            "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
            "[CV] .. C=1000, gamma=0.01, kernel=linear, score=-1.170, total= 4.3min\n",
            "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
            "[CV] .. C=1000, gamma=0.01, kernel=linear, score=-1.090, total= 4.5min\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] .... C=1000, gamma=0.001, kernel=rbf, score=-1.030, total=   1.8s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] .... C=1000, gamma=0.001, kernel=rbf, score=-1.036, total=   1.8s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] .... C=1000, gamma=0.001, kernel=rbf, score=-1.009, total=   1.9s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] .... C=1000, gamma=0.001, kernel=rbf, score=-1.133, total=   1.9s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] .... C=1000, gamma=0.001, kernel=rbf, score=-1.087, total=   1.8s\n",
            "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
            "[CV] . C=1000, gamma=0.001, kernel=linear, score=-1.060, total= 4.4min\n",
            "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
            "[CV] . C=1000, gamma=0.001, kernel=linear, score=-1.057, total= 4.5min\n",
            "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
            "[CV] . C=1000, gamma=0.001, kernel=linear, score=-1.047, total= 4.5min\n",
            "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
            "[CV] . C=1000, gamma=0.001, kernel=linear, score=-1.170, total= 4.3min\n",
            "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
            "[CV] . C=1000, gamma=0.001, kernel=linear, score=-1.090, total= 4.6min\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] ... C=1000, gamma=0.0001, kernel=rbf, score=-1.046, total=   1.2s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] ... C=1000, gamma=0.0001, kernel=rbf, score=-1.046, total=   1.5s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] ... C=1000, gamma=0.0001, kernel=rbf, score=-1.031, total=   1.2s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] ... C=1000, gamma=0.0001, kernel=rbf, score=-1.153, total=   1.3s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] ... C=1000, gamma=0.0001, kernel=rbf, score=-1.093, total=   1.3s\n",
            "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=linear, score=-1.060, total= 4.6min\n",
            "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=linear, score=-1.057, total= 4.5min\n",
            "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=linear, score=-1.047, total= 4.7min\n",
            "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=linear, score=-1.170, total= 4.3min\n",
            "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=linear, score=-1.090, total= 4.4min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 250 out of 250 | elapsed: 150.7min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best score for SVM is: -1.0578897651069958\n",
            "The best parameters for SVMM are: SVR(C=10, gamma=0.01)\n",
            "MSE of SVM on training data =  1.0489138523405188\n",
            "MSE of SVM on testing data =  1.085242944179051\n",
            "difference in MSE of SVM =  0.03632909183853217\n"
          ]
        }
      ],
      "source": [
        "# defining parameter grid\n",
        "SVR_paramgrid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "\n",
        "grid_svm = GridSearchCV(SVR(), SVR_paramgrid, refit = True, cv=5, verbose = 3, scoring=scorer)\n",
        "\n",
        "# fit the grid search model\n",
        "grid_svm.fit(x_train_scale, y_train)\n",
        "\n",
        "# check the best hyperparameters and the best test score from cross validation\n",
        "print('The best score for SVM is:',grid_svm.best_score_)\n",
        "print('The best parameters for SVMM are:',grid_svm.best_estimator_)\n",
        "\n",
        "# Building final SVM model with the best hyperparameters\n",
        "svm_model = grid_svm.best_estimator_\n",
        "\n",
        "# predict\n",
        "SVM_fit = svm_model.fit(x_train_scale,y_train)\n",
        "ytrain_svm_shots = SVM_fit.predict(x_train_scale)\n",
        "ytest_svm_shots = SVM_fit.predict(x_test_scale)\n",
        "\n",
        "# evaluate\n",
        "mse_svm_shots_train = mean_squared_error(ytrain_svm_shots,y_train)\n",
        "mse_svm_shots_test = mean_squared_error(ytest_svm_shots,y_test)\n",
        "genloss_svm_shots = mse_svm_shots_test - mse_svm_shots_train\n",
        "\n",
        "print(\"MSE of SVM on training data = \",mse_svm_shots_train)\n",
        "print(\"MSE of SVM on testing data = \",mse_svm_shots_test)\n",
        "print(\"difference in MSE of SVM = \",genloss_svm_shots)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSG_38oSlA_V"
      },
      "source": [
        "##### Model Evaluation and Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bxa-tTfWlKkE",
        "outputId": "3e9adf1f-ebcd-4f26-8942-321dc3033358"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(<Figure size 864x576 with 1 Axes>,\n",
              " <AxesSubplot:xlabel='Regression Models for shot based expected match value', ylabel='Mean Squared Error'>)"
            ]
          },
          "execution_count": 313,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# function to produce a bar plot visualising performance and the generalisation loss to aid our decision making\n",
        "def barplot(training, testing, diff,shot):\n",
        "    #width of bar\n",
        "    barwidth =  0.25\n",
        "    fig = plt.subplots(figsize = (12,8))\n",
        "\n",
        "    # position of bar on x axis\n",
        "    br1 = np.arange(len(training))\n",
        "    br2 = [x + barwidth for x in br1]\n",
        "    br3 = [x + barwidth for x in br2]\n",
        "\n",
        "    # make the plot\n",
        "    plt.bar(br1, training, color ='r', width = barwidth, edgecolor='grey',label='training')\n",
        "    plt.bar(br2, testing, color ='g', width = barwidth, edgecolor='grey', label ='testing')\n",
        "    plt.bar(br3, diff, color ='b', width = barwidth, edgecolor ='grey',label ='loss')\n",
        "\n",
        "    # labelling\n",
        "    plt.xticks([r + barwidth for r in range(len(training))],['LR','RF','SVM'])\n",
        "    plt.legend()\n",
        "    plt.xlabel(shot)\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "    plt.show()\n",
        "\n",
        "    return fig\n",
        "\n",
        "# listing the mean squared erros as input into bar plot\n",
        "shots_training_eva = [mse_lr_shots_train, mse_rf_shots_train, mse_svm_shots_train]\n",
        "shots_testing_eva = [mse_lr_shots_test, mse_rf_shots_test, mse_svm_shots_test]\n",
        "shots_diff_eva = [genloss_lr_shots, genloss_rf_shots, genloss_svm_shots]\n",
        "\n",
        "# plotting\n",
        "shots_plot = barplot(shots_training_eva,shots_testing_eva,shots_diff_eva,'Regression Models for shot based expected match value')\n",
        "shots_plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pACD2VHe7YYU"
      },
      "source": [
        "SVM has the seecond smallest mean squared error but it has a much lower generalisation loss compared to RF. Hence, it was chosen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZAToGH5lbPr"
      },
      "source": [
        "#### Non-shot based expected match value model\n",
        "The same steps were repeated to build our non-shot based expected match value model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5GjGxPZ7YYX"
      },
      "source": [
        "Again, we split training data into training and validation sets for performance evaluation. We also scale our input features before feeding into our models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8m1dQyupmOBW"
      },
      "outputs": [],
      "source": [
        "# splitting training and testing data\n",
        "x_train2, x_test2, y_train2, y_test2 = train_test_split(x_nonshot, y_nonshot, test_size = 0.2, random_state=42)\n",
        "\n",
        "# standardise\n",
        "scaler = StandardScaler()\n",
        "x_train_scale2 = scaler.fit_transform(x_train2)\n",
        "x_test_scale2 = scaler.transform(x_test2)\n",
        "x_nonshot_scale = scaler.transform(x_nonshot)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKqjAikCmRkF"
      },
      "source": [
        "##### Multivariate Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRazCZzmOnWd",
        "outputId": "39cb0ef1-c642-48e9-e367-43153d582c41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE of linear regressor on training data =  1.3835395867250249\n",
            "MSE of linear regressor on testing data =  1.4287510232811902\n",
            "difference in MSE of linear regressor =  0.04521143655616533\n"
          ]
        }
      ],
      "source": [
        "# fit\n",
        "lr_nonshot = LinearRegression()\n",
        "lr_nonshot.fit(x_train_scale2,y_train2)\n",
        "\n",
        "# predict\n",
        "ytrain_lr_nonshot = lr_nonshot.predict(x_train_scale2)\n",
        "ytest_lr_nonshot = lr_nonshot.predict(x_test_scale2)\n",
        "\n",
        "# evaluate\n",
        "mse_lr_nonshot_train = mean_squared_error(ytrain_lr_nonshot,y_train2)\n",
        "mse_lr_nonshot_test = mean_squared_error(ytest_lr_nonshot,y_test2)\n",
        "genloss_lr_nonshot = mse_lr_nonshot_test - mse_lr_nonshot_train\n",
        "\n",
        "print(\"MSE of linear regressor on training data = \",mse_lr_nonshot_train)\n",
        "print(\"MSE of linear regressor on testing data = \",mse_lr_nonshot_test)\n",
        "print(\"difference in MSE of linear regressor = \",genloss_lr_nonshot)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxL8jkYM7YYX",
        "outputId": "ece6e1f2-07fd-4ddd-9956-777b561bdc2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nested Cross Validation mean test score: -1.3874651723009088\n"
          ]
        }
      ],
      "source": [
        "# cross validation\n",
        "nonshot_lr_cv = cross_val_score(lr_nonshot, X=x_train_scale2, y=y_train2, cv=5, scoring=scorer)\n",
        "nonshot_lr_err = nonshot_lr_cv.mean()\n",
        "print('Nested Cross Validation mean test score:',nonshot_lr_err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4OTCqj47YYX"
      },
      "source": [
        "For the same reasons as above, we choose to use mean squared error from our validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVUfTnftPHsY",
        "outputId": "c273a365-e8a5-4218-ae87-822cf65e0369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "P     0.245753\n",
              "C     0.244139\n",
              "CR   -0.349918\n",
              "dtype: float64"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checking parameters for non_shot based expected match value\n",
        "param_nonshot = pd.Series(lr_nonshot.coef_, index=x_nonshot.columns)\n",
        "np.random.seed(1)\n",
        "err_nonshot = np.std([lr_nonshot.fit(*resample(x_nonshot,y_nonshot)).coef_ for i in range(1000)],0)\n",
        "param_nonshot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_cWGswA7YYX"
      },
      "source": [
        "These values show the coefficients for our input variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ktIauGfnWbO"
      },
      "source": [
        "##### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-bQKrBAVilo",
        "outputId": "6c92a481-842c-49e9-b15c-4335a96cda59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   10.8s\n",
            "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  5.4min\n",
            "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed:  8.5min\n",
            "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed: 12.4min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-1.4214740533336951\n",
            "RandomForestRegressor(max_depth=90, max_features=2, min_samples_leaf=5,\n",
            "                      min_samples_split=12, n_estimators=200)\n",
            "MSE of random forest regressor on training data =  0.9724646232981622\n",
            "MSE of random forest regressor on testing data =  1.4492603636460581\n",
            "difference in MSE of random forest regressor =  0.47679574034789596\n"
          ]
        }
      ],
      "source": [
        "# Create a base model\n",
        "rf2 = RandomForestRegressor()\n",
        "\n",
        "# Instantiate the grid search model\n",
        "grid_rf2 = GridSearchCV(estimator = rf2, param_grid = RF_paramgrid,\n",
        "                          cv = 5, n_jobs = -1, verbose = 2, scoring=scorer)\n",
        "# Fit the grid search model\n",
        "grid_rf2.fit(x_train_scale2, y_train2)\n",
        "\n",
        "# checking values of hyperparameters and best test score\n",
        "print (grid_rf2.best_score_)\n",
        "print (grid_rf2.best_estimator_)\n",
        "\n",
        "# build the final model with the optimum hyperparameters\n",
        "rf2_model = grid_rf2.best_estimator_\n",
        "\n",
        "# fit the final model\n",
        "RF2_fit = rf2_model.fit(x_train_scale2, y_train2)\n",
        "\n",
        "# predict\n",
        "ytrain_rf_nonshot = RF2_fit.predict(x_train_scale2)\n",
        "ytest_rf_nonshot = RF2_fit.predict(x_test_scale2)\n",
        "\n",
        "# evaluate\n",
        "mse_rf_nonshot_train = mean_squared_error(ytrain_rf_nonshot,y_train2)\n",
        "mse_rf_nonshot_test = mean_squared_error(ytest_rf_nonshot,y_test2)\n",
        "genloss_rf_nonshot = mse_rf_nonshot_test - mse_rf_nonshot_train\n",
        "\n",
        "print(\"MSE of random forest regressor on training data = \",mse_rf_nonshot_train)\n",
        "print(\"MSE of random forest regressor on testing data = \",mse_rf_nonshot_test)\n",
        "print(\"difference in MSE of random forest regressor = \",genloss_rf_nonshot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQg2EP-_oC3T"
      },
      "source": [
        "##### Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATqYYavsV32V",
        "outputId": "ff79a3ab-2ded-4cc7-8fe9-f69cd9d4f266"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] ......... C=0.1, gamma=1, kernel=rbf, score=-1.415, total=   1.7s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] ......... C=0.1, gamma=1, kernel=rbf, score=-1.466, total=   1.6s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.1s remaining:    0.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] ......... C=0.1, gamma=1, kernel=rbf, score=-1.463, total=   1.7s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] ......... C=0.1, gamma=1, kernel=rbf, score=-1.644, total=   1.6s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] ......... C=0.1, gamma=1, kernel=rbf, score=-1.565, total=   1.6s\n",
            "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=0.1, gamma=1, kernel=linear, score=-1.364, total=   2.9s\n",
            "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=0.1, gamma=1, kernel=linear, score=-1.412, total=   2.8s\n",
            "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=0.1, gamma=1, kernel=linear, score=-1.421, total=   2.4s\n",
            "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=0.1, gamma=1, kernel=linear, score=-1.600, total=   3.1s\n",
            "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=0.1, gamma=1, kernel=linear, score=-1.516, total=   3.1s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=0.1, gamma=0.1, kernel=rbf, score=-1.353, total=   1.3s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=0.1, gamma=0.1, kernel=rbf, score=-1.386, total=   1.3s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=0.1, gamma=0.1, kernel=rbf, score=-1.376, total=   1.3s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=0.1, gamma=0.1, kernel=rbf, score=-1.576, total=   1.3s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=0.1, gamma=0.1, kernel=rbf, score=-1.473, total=   1.3s\n",
            "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=0.1, gamma=0.1, kernel=linear, score=-1.364, total=   2.8s\n",
            "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=0.1, gamma=0.1, kernel=linear, score=-1.412, total=   2.8s\n",
            "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=0.1, gamma=0.1, kernel=linear, score=-1.421, total=   2.5s\n",
            "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=0.1, gamma=0.1, kernel=linear, score=-1.600, total=   3.1s\n",
            "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=0.1, gamma=0.1, kernel=linear, score=-1.516, total=   3.1s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=0.1, gamma=0.01, kernel=rbf, score=-1.328, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=0.1, gamma=0.01, kernel=rbf, score=-1.370, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=0.1, gamma=0.01, kernel=rbf, score=-1.371, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=0.1, gamma=0.01, kernel=rbf, score=-1.540, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=0.1, gamma=0.01, kernel=rbf, score=-1.444, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=0.1, gamma=0.01, kernel=linear, score=-1.364, total=   2.7s\n",
            "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=0.1, gamma=0.01, kernel=linear, score=-1.412, total=   2.8s\n",
            "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=0.1, gamma=0.01, kernel=linear, score=-1.421, total=   2.5s\n",
            "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=0.1, gamma=0.01, kernel=linear, score=-1.600, total=   3.1s\n",
            "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=0.1, gamma=0.01, kernel=linear, score=-1.516, total=   3.3s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=0.1, gamma=0.001, kernel=rbf, score=-1.323, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=0.1, gamma=0.001, kernel=rbf, score=-1.371, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=0.1, gamma=0.001, kernel=rbf, score=-1.374, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=0.1, gamma=0.001, kernel=rbf, score=-1.535, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=0.1, gamma=0.001, kernel=rbf, score=-1.454, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=0.1, gamma=0.001, kernel=linear, score=-1.364, total=   2.7s\n",
            "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=0.1, gamma=0.001, kernel=linear, score=-1.412, total=   3.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=0.1, gamma=0.001, kernel=linear, score=-1.421, total=   2.6s\n",
            "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=0.1, gamma=0.001, kernel=linear, score=-1.600, total=   3.2s\n",
            "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=0.1, gamma=0.001, kernel=linear, score=-1.516, total=   3.1s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=0.1, gamma=0.0001, kernel=rbf, score=-1.385, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=0.1, gamma=0.0001, kernel=rbf, score=-1.440, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=0.1, gamma=0.0001, kernel=rbf, score=-1.437, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=0.1, gamma=0.0001, kernel=rbf, score=-1.616, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=0.1, gamma=0.0001, kernel=rbf, score=-1.537, total=   1.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=0.1, gamma=0.0001, kernel=linear, score=-1.364, total=   2.9s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=0.1, gamma=0.0001, kernel=linear, score=-1.412, total=   2.9s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=0.1, gamma=0.0001, kernel=linear, score=-1.421, total=   2.5s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=0.1, gamma=0.0001, kernel=linear, score=-1.600, total=   3.2s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=0.1, gamma=0.0001, kernel=linear, score=-1.516, total=   3.2s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ........... C=1, gamma=1, kernel=rbf, score=-1.581, total=   2.1s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ........... C=1, gamma=1, kernel=rbf, score=-1.563, total=   2.0s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ........... C=1, gamma=1, kernel=rbf, score=-1.539, total=   2.1s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ........... C=1, gamma=1, kernel=rbf, score=-1.759, total=   2.1s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ........... C=1, gamma=1, kernel=rbf, score=-1.691, total=   2.0s\n",
            "[CV] C=1, gamma=1, kernel=linear .....................................\n",
            "[CV] ........ C=1, gamma=1, kernel=linear, score=-1.364, total=  15.7s\n",
            "[CV] C=1, gamma=1, kernel=linear .....................................\n",
            "[CV] ........ C=1, gamma=1, kernel=linear, score=-1.413, total=  15.3s\n",
            "[CV] C=1, gamma=1, kernel=linear .....................................\n",
            "[CV] ........ C=1, gamma=1, kernel=linear, score=-1.421, total=  14.3s\n",
            "[CV] C=1, gamma=1, kernel=linear .....................................\n",
            "[CV] ........ C=1, gamma=1, kernel=linear, score=-1.600, total=  18.4s\n",
            "[CV] C=1, gamma=1, kernel=linear .....................................\n",
            "[CV] ........ C=1, gamma=1, kernel=linear, score=-1.516, total=  16.8s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] ......... C=1, gamma=0.1, kernel=rbf, score=-1.400, total=   1.5s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] ......... C=1, gamma=0.1, kernel=rbf, score=-1.414, total=   1.6s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] ......... C=1, gamma=0.1, kernel=rbf, score=-1.433, total=   1.6s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] ......... C=1, gamma=0.1, kernel=rbf, score=-1.602, total=   1.5s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] ......... C=1, gamma=0.1, kernel=rbf, score=-1.505, total=   1.5s\n",
            "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
            "[CV] ...... C=1, gamma=0.1, kernel=linear, score=-1.364, total=  16.4s\n",
            "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
            "[CV] ...... C=1, gamma=0.1, kernel=linear, score=-1.413, total=  15.0s\n",
            "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
            "[CV] ...... C=1, gamma=0.1, kernel=linear, score=-1.421, total=  14.8s\n",
            "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
            "[CV] ...... C=1, gamma=0.1, kernel=linear, score=-1.600, total=  18.2s\n",
            "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
            "[CV] ...... C=1, gamma=0.1, kernel=linear, score=-1.516, total=  17.1s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ........ C=1, gamma=0.01, kernel=rbf, score=-1.321, total=   1.1s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ........ C=1, gamma=0.01, kernel=rbf, score=-1.358, total=   1.0s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ........ C=1, gamma=0.01, kernel=rbf, score=-1.390, total=   1.1s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ........ C=1, gamma=0.01, kernel=rbf, score=-1.529, total=   1.1s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ........ C=1, gamma=0.01, kernel=rbf, score=-1.434, total=   1.1s\n",
            "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
            "[CV] ..... C=1, gamma=0.01, kernel=linear, score=-1.364, total=  16.0s\n",
            "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
            "[CV] ..... C=1, gamma=0.01, kernel=linear, score=-1.413, total=  14.8s\n",
            "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
            "[CV] ..... C=1, gamma=0.01, kernel=linear, score=-1.421, total=  14.2s\n",
            "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
            "[CV] ..... C=1, gamma=0.01, kernel=linear, score=-1.600, total=  18.9s\n",
            "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
            "[CV] ..... C=1, gamma=0.01, kernel=linear, score=-1.516, total=  16.7s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ....... C=1, gamma=0.001, kernel=rbf, score=-1.312, total=   1.2s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ....... C=1, gamma=0.001, kernel=rbf, score=-1.360, total=   1.3s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ....... C=1, gamma=0.001, kernel=rbf, score=-1.364, total=   1.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ....... C=1, gamma=0.001, kernel=rbf, score=-1.519, total=   1.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ....... C=1, gamma=0.001, kernel=rbf, score=-1.435, total=   1.1s\n",
            "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
            "[CV] .... C=1, gamma=0.001, kernel=linear, score=-1.364, total=  22.4s\n",
            "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
            "[CV] .... C=1, gamma=0.001, kernel=linear, score=-1.413, total=  22.1s\n",
            "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
            "[CV] .... C=1, gamma=0.001, kernel=linear, score=-1.421, total=  14.3s\n",
            "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
            "[CV] .... C=1, gamma=0.001, kernel=linear, score=-1.600, total=  17.9s\n",
            "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
            "[CV] .... C=1, gamma=0.001, kernel=linear, score=-1.516, total=  16.7s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ...... C=1, gamma=0.0001, kernel=rbf, score=-1.338, total=   1.1s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ...... C=1, gamma=0.0001, kernel=rbf, score=-1.388, total=   1.1s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ...... C=1, gamma=0.0001, kernel=rbf, score=-1.393, total=   1.1s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ...... C=1, gamma=0.0001, kernel=rbf, score=-1.566, total=   1.1s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ...... C=1, gamma=0.0001, kernel=rbf, score=-1.483, total=   1.1s\n",
            "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
            "[CV] ... C=1, gamma=0.0001, kernel=linear, score=-1.364, total=  15.9s\n",
            "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
            "[CV] ... C=1, gamma=0.0001, kernel=linear, score=-1.413, total=  15.1s\n",
            "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
            "[CV] ... C=1, gamma=0.0001, kernel=linear, score=-1.421, total=  14.3s\n",
            "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
            "[CV] ... C=1, gamma=0.0001, kernel=linear, score=-1.600, total=  18.2s\n",
            "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
            "[CV] ... C=1, gamma=0.0001, kernel=linear, score=-1.516, total=  17.1s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] .......... C=10, gamma=1, kernel=rbf, score=-2.079, total=   4.1s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] .......... C=10, gamma=1, kernel=rbf, score=-2.176, total=   3.8s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] .......... C=10, gamma=1, kernel=rbf, score=-2.030, total=   3.9s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] .......... C=10, gamma=1, kernel=rbf, score=-2.226, total=   3.9s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] .......... C=10, gamma=1, kernel=rbf, score=-2.166, total=   3.9s\n",
            "[CV] C=10, gamma=1, kernel=linear ....................................\n",
            "[CV] ....... C=10, gamma=1, kernel=linear, score=-1.329, total= 1.8min\n",
            "[CV] C=10, gamma=1, kernel=linear ....................................\n",
            "[CV] ....... C=10, gamma=1, kernel=linear, score=-1.363, total= 1.9min\n",
            "[CV] C=10, gamma=1, kernel=linear ....................................\n",
            "[CV] ....... C=10, gamma=1, kernel=linear, score=-1.400, total= 1.5min\n",
            "[CV] C=10, gamma=1, kernel=linear ....................................\n",
            "[CV] ....... C=10, gamma=1, kernel=linear, score=-1.513, total= 2.3min\n",
            "[CV] C=10, gamma=1, kernel=linear ....................................\n",
            "[CV] ....... C=10, gamma=1, kernel=linear, score=-1.451, total= 2.1min\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ........ C=10, gamma=0.1, kernel=rbf, score=-1.620, total=   3.7s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ........ C=10, gamma=0.1, kernel=rbf, score=-1.603, total=   3.7s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ........ C=10, gamma=0.1, kernel=rbf, score=-1.654, total=   3.7s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ........ C=10, gamma=0.1, kernel=rbf, score=-1.811, total=   3.8s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ........ C=10, gamma=0.1, kernel=rbf, score=-1.699, total=   3.7s\n",
            "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
            "[CV] ..... C=10, gamma=0.1, kernel=linear, score=-1.329, total= 1.9min\n",
            "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
            "[CV] ..... C=10, gamma=0.1, kernel=linear, score=-1.363, total= 2.1min\n",
            "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
            "[CV] ..... C=10, gamma=0.1, kernel=linear, score=-1.400, total= 1.6min\n",
            "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
            "[CV] ..... C=10, gamma=0.1, kernel=linear, score=-1.513, total= 2.4min\n",
            "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
            "[CV] ..... C=10, gamma=0.1, kernel=linear, score=-1.451, total= 2.0min\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ....... C=10, gamma=0.01, kernel=rbf, score=-1.336, total=   1.5s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ....... C=10, gamma=0.01, kernel=rbf, score=-1.366, total=   1.6s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ....... C=10, gamma=0.01, kernel=rbf, score=-1.412, total=   1.6s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ....... C=10, gamma=0.01, kernel=rbf, score=-1.540, total=   1.5s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ....... C=10, gamma=0.01, kernel=rbf, score=-1.454, total=   1.5s\n",
            "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
            "[CV] .... C=10, gamma=0.01, kernel=linear, score=-1.329, total= 1.9min\n",
            "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
            "[CV] .... C=10, gamma=0.01, kernel=linear, score=-1.363, total= 2.0min\n",
            "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
            "[CV] .... C=10, gamma=0.01, kernel=linear, score=-1.400, total= 1.6min\n",
            "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
            "[CV] .... C=10, gamma=0.01, kernel=linear, score=-1.513, total= 2.4min\n",
            "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
            "[CV] .... C=10, gamma=0.01, kernel=linear, score=-1.451, total= 2.1min\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ...... C=10, gamma=0.001, kernel=rbf, score=-1.313, total=   1.3s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ...... C=10, gamma=0.001, kernel=rbf, score=-1.362, total=   1.3s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ...... C=10, gamma=0.001, kernel=rbf, score=-1.371, total=   1.2s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ...... C=10, gamma=0.001, kernel=rbf, score=-1.524, total=   1.2s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ...... C=10, gamma=0.001, kernel=rbf, score=-1.433, total=   1.2s\n",
            "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
            "[CV] ... C=10, gamma=0.001, kernel=linear, score=-1.329, total= 1.9min\n",
            "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
            "[CV] ... C=10, gamma=0.001, kernel=linear, score=-1.363, total= 2.0min\n",
            "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
            "[CV] ... C=10, gamma=0.001, kernel=linear, score=-1.400, total= 1.6min\n",
            "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
            "[CV] ... C=10, gamma=0.001, kernel=linear, score=-1.513, total= 2.3min\n",
            "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
            "[CV] ... C=10, gamma=0.001, kernel=linear, score=-1.451, total= 2.1min\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ..... C=10, gamma=0.0001, kernel=rbf, score=-1.315, total=   1.1s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ..... C=10, gamma=0.0001, kernel=rbf, score=-1.361, total=   1.1s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ..... C=10, gamma=0.0001, kernel=rbf, score=-1.382, total=   1.2s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ..... C=10, gamma=0.0001, kernel=rbf, score=-1.524, total=   1.1s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ..... C=10, gamma=0.0001, kernel=rbf, score=-1.444, total=   1.1s\n",
            "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
            "[CV] .. C=10, gamma=0.0001, kernel=linear, score=-1.329, total= 1.9min\n",
            "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
            "[CV] .. C=10, gamma=0.0001, kernel=linear, score=-1.363, total= 2.0min\n",
            "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
            "[CV] .. C=10, gamma=0.0001, kernel=linear, score=-1.400, total= 1.6min\n",
            "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
            "[CV] .. C=10, gamma=0.0001, kernel=linear, score=-1.513, total= 2.3min\n",
            "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
            "[CV] .. C=10, gamma=0.0001, kernel=linear, score=-1.451, total= 2.1min\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] ......... C=100, gamma=1, kernel=rbf, score=-3.132, total=  11.2s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] ......... C=100, gamma=1, kernel=rbf, score=-3.321, total=  12.2s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] ......... C=100, gamma=1, kernel=rbf, score=-3.384, total=  11.4s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] ......... C=100, gamma=1, kernel=rbf, score=-3.408, total=  11.2s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] ......... C=100, gamma=1, kernel=rbf, score=-3.404, total=  10.6s\n",
            "[CV] C=100, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=100, gamma=1, kernel=linear, score=-2.075, total= 1.8min\n",
            "[CV] C=100, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=100, gamma=1, kernel=linear, score=-1.412, total= 2.0min\n",
            "[CV] C=100, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=100, gamma=1, kernel=linear, score=-1.751, total= 2.0min\n",
            "[CV] C=100, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=100, gamma=1, kernel=linear, score=-1.624, total= 1.6min\n",
            "[CV] C=100, gamma=1, kernel=linear ...................................\n",
            "[CV] ...... C=100, gamma=1, kernel=linear, score=-1.621, total= 1.7min\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=100, gamma=0.1, kernel=rbf, score=-2.111, total=  27.4s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=100, gamma=0.1, kernel=rbf, score=-2.060, total=  26.9s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=100, gamma=0.1, kernel=rbf, score=-2.051, total=  28.6s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=100, gamma=0.1, kernel=rbf, score=-2.129, total=  27.2s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ....... C=100, gamma=0.1, kernel=rbf, score=-2.209, total=  26.6s\n",
            "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=100, gamma=0.1, kernel=linear, score=-2.075, total= 1.8min\n",
            "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=100, gamma=0.1, kernel=linear, score=-1.412, total= 2.0min\n",
            "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=100, gamma=0.1, kernel=linear, score=-1.751, total= 2.0min\n",
            "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=100, gamma=0.1, kernel=linear, score=-1.624, total= 1.6min\n",
            "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
            "[CV] .... C=100, gamma=0.1, kernel=linear, score=-1.621, total= 1.7min\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=100, gamma=0.01, kernel=rbf, score=-1.370, total=   3.9s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=100, gamma=0.01, kernel=rbf, score=-1.372, total=   4.5s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=100, gamma=0.01, kernel=rbf, score=-1.450, total=   4.6s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=100, gamma=0.01, kernel=rbf, score=-1.587, total=   4.4s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ...... C=100, gamma=0.01, kernel=rbf, score=-1.504, total=   4.4s\n",
            "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=100, gamma=0.01, kernel=linear, score=-2.075, total= 1.8min\n",
            "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=100, gamma=0.01, kernel=linear, score=-1.412, total= 2.0min\n",
            "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=100, gamma=0.01, kernel=linear, score=-1.751, total= 2.0min\n",
            "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=100, gamma=0.01, kernel=linear, score=-1.624, total= 1.6min\n",
            "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
            "[CV] ... C=100, gamma=0.01, kernel=linear, score=-1.621, total= 1.8min\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=100, gamma=0.001, kernel=rbf, score=-1.312, total=   2.0s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=100, gamma=0.001, kernel=rbf, score=-1.362, total=   2.0s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=100, gamma=0.001, kernel=rbf, score=-1.383, total=   2.2s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=100, gamma=0.001, kernel=rbf, score=-1.527, total=   2.0s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ..... C=100, gamma=0.001, kernel=rbf, score=-1.432, total=   2.1s\n",
            "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=100, gamma=0.001, kernel=linear, score=-2.075, total= 1.8min\n",
            "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=100, gamma=0.001, kernel=linear, score=-1.412, total= 2.1min\n",
            "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=100, gamma=0.001, kernel=linear, score=-1.751, total= 2.0min\n",
            "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=100, gamma=0.001, kernel=linear, score=-1.624, total= 1.6min\n",
            "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
            "[CV] .. C=100, gamma=0.001, kernel=linear, score=-1.621, total= 1.8min\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=100, gamma=0.0001, kernel=rbf, score=-1.311, total=   1.3s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=100, gamma=0.0001, kernel=rbf, score=-1.356, total=   1.3s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=100, gamma=0.0001, kernel=rbf, score=-1.388, total=   1.4s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=100, gamma=0.0001, kernel=rbf, score=-1.520, total=   1.4s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] .... C=100, gamma=0.0001, kernel=rbf, score=-1.431, total=   1.4s\n",
            "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=100, gamma=0.0001, kernel=linear, score=-2.075, total= 1.8min\n",
            "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=100, gamma=0.0001, kernel=linear, score=-1.412, total= 2.1min\n",
            "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=100, gamma=0.0001, kernel=linear, score=-1.751, total= 2.0min\n",
            "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=100, gamma=0.0001, kernel=linear, score=-1.624, total= 1.6min\n",
            "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] . C=100, gamma=0.0001, kernel=linear, score=-1.621, total= 1.8min\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ........ C=1000, gamma=1, kernel=rbf, score=-6.581, total=  45.3s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ........ C=1000, gamma=1, kernel=rbf, score=-7.805, total=  46.9s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ........ C=1000, gamma=1, kernel=rbf, score=-7.632, total=  43.1s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ........ C=1000, gamma=1, kernel=rbf, score=-7.718, total=  37.2s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ........ C=1000, gamma=1, kernel=rbf, score=-7.076, total=  37.8s\n",
            "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
            "[CV] ..... C=1000, gamma=1, kernel=linear, score=-2.097, total= 3.7min\n",
            "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
            "[CV] ..... C=1000, gamma=1, kernel=linear, score=-5.883, total= 3.0min\n",
            "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
            "[CV] ..... C=1000, gamma=1, kernel=linear, score=-8.279, total= 2.4min\n",
            "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
            "[CV] ..... C=1000, gamma=1, kernel=linear, score=-2.110, total= 2.7min\n",
            "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
            "[CV] ..... C=1000, gamma=1, kernel=linear, score=-5.372, total= 2.3min\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ...... C=1000, gamma=0.1, kernel=rbf, score=-3.686, total= 5.3min\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ...... C=1000, gamma=0.1, kernel=rbf, score=-3.421, total= 5.3min\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ...... C=1000, gamma=0.1, kernel=rbf, score=-3.544, total= 5.4min\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ...... C=1000, gamma=0.1, kernel=rbf, score=-3.500, total= 5.4min\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ...... C=1000, gamma=0.1, kernel=rbf, score=-3.762, total= 5.6min\n",
            "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
            "[CV] ... C=1000, gamma=0.1, kernel=linear, score=-2.097, total= 3.7min\n",
            "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
            "[CV] ... C=1000, gamma=0.1, kernel=linear, score=-5.883, total= 2.8min\n",
            "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
            "[CV] ... C=1000, gamma=0.1, kernel=linear, score=-8.279, total= 2.3min\n",
            "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
            "[CV] ... C=1000, gamma=0.1, kernel=linear, score=-2.110, total= 2.6min\n",
            "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
            "[CV] ... C=1000, gamma=0.1, kernel=linear, score=-5.372, total= 2.2min\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ..... C=1000, gamma=0.01, kernel=rbf, score=-1.421, total=  29.3s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ..... C=1000, gamma=0.01, kernel=rbf, score=-1.411, total=  27.6s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ..... C=1000, gamma=0.01, kernel=rbf, score=-1.687, total=  30.4s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ..... C=1000, gamma=0.01, kernel=rbf, score=-1.656, total=  29.9s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ..... C=1000, gamma=0.01, kernel=rbf, score=-1.631, total=  29.9s\n",
            "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
            "[CV] .. C=1000, gamma=0.01, kernel=linear, score=-2.097, total= 3.7min\n",
            "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
            "[CV] .. C=1000, gamma=0.01, kernel=linear, score=-5.883, total= 2.8min\n",
            "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
            "[CV] .. C=1000, gamma=0.01, kernel=linear, score=-8.279, total= 2.4min\n",
            "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
            "[CV] .. C=1000, gamma=0.01, kernel=linear, score=-2.110, total= 2.5min\n",
            "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
            "[CV] .. C=1000, gamma=0.01, kernel=linear, score=-5.372, total= 2.1min\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] .... C=1000, gamma=0.001, kernel=rbf, score=-1.314, total=   7.4s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] .... C=1000, gamma=0.001, kernel=rbf, score=-1.364, total=   6.9s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] .... C=1000, gamma=0.001, kernel=rbf, score=-1.396, total=   6.5s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] .... C=1000, gamma=0.001, kernel=rbf, score=-1.530, total=   6.0s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] .... C=1000, gamma=0.001, kernel=rbf, score=-1.436, total=   5.9s\n",
            "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
            "[CV] . C=1000, gamma=0.001, kernel=linear, score=-2.097, total= 3.7min\n",
            "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
            "[CV] . C=1000, gamma=0.001, kernel=linear, score=-5.883, total= 2.9min\n",
            "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
            "[CV] . C=1000, gamma=0.001, kernel=linear, score=-8.279, total= 2.4min\n",
            "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
            "[CV] . C=1000, gamma=0.001, kernel=linear, score=-2.110, total= 2.5min\n",
            "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
            "[CV] . C=1000, gamma=0.001, kernel=linear, score=-5.372, total= 2.1min\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] ... C=1000, gamma=0.0001, kernel=rbf, score=-1.311, total=   2.2s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] ... C=1000, gamma=0.0001, kernel=rbf, score=-1.359, total=   2.0s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] ... C=1000, gamma=0.0001, kernel=rbf, score=-1.431, total=   2.1s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] ... C=1000, gamma=0.0001, kernel=rbf, score=-1.525, total=   2.2s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] ... C=1000, gamma=0.0001, kernel=rbf, score=-1.432, total=   2.3s\n",
            "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=linear, score=-2.097, total= 3.8min\n",
            "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=linear, score=-5.883, total= 2.9min\n",
            "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=linear, score=-8.279, total= 2.3min\n",
            "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=linear, score=-2.110, total= 2.6min\n",
            "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=linear, score=-5.372, total= 2.1min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 250 out of 250 | elapsed: 212.0min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best score for SVM is: -1.3981393444149872\n",
            "The best parameters for SVMM are: SVR(C=1, gamma=0.001)\n",
            "MSE of SVM on training data =  1.4725724119100394\n",
            "MSE of SVM on testing data =  1.4802988070256082\n",
            "difference in MSE of SVM =  0.007726395115568829\n"
          ]
        }
      ],
      "source": [
        "grid_svm2 = GridSearchCV(SVR(), SVR_paramgrid, refit = True, cv=5, verbose = 3, scoring=scorer)\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid_svm2.fit(x_train2, y_train2)\n",
        "\n",
        "# check best hyperparameter and test scores\n",
        "print('The best score for SVM is:',grid_svm2.best_score_)\n",
        "print('The best parameters for SVMM are:',grid_svm2.best_estimator_)\n",
        "\n",
        "# Building final SVM model with the best hyperparameters\n",
        "svm2_model = grid_svm2.best_estimator_\n",
        "\n",
        "# fit the final model\n",
        "SVM2_fit = svm2_model.fit(x_train_scale2,y_train2)\n",
        "\n",
        "#predict\n",
        "ytrain_svm_nonshot = SVM2_fit.predict(x_train_scale2)\n",
        "ytest_svm_nonshot = SVM2_fit.predict(x_test_scale2)\n",
        "\n",
        "# evaluate\n",
        "mse_svm_nonshot_train = mean_squared_error(ytrain_svm_nonshot,y_train2)\n",
        "mse_svm_nonshot_test = mean_squared_error(ytest_svm_nonshot,y_test2)\n",
        "genloss_svm_nonshot = mse_svm_nonshot_test - mse_svm_nonshot_train\n",
        "\n",
        "print(\"MSE of SVM on training data = \",mse_svm_nonshot_train)\n",
        "print(\"MSE of SVM on testing data = \",mse_svm_nonshot_test)\n",
        "print(\"difference in MSE of SVM = \",genloss_svm_nonshot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPIgtGJopIH9"
      },
      "source": [
        "##### Model Evaluation and Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86lvjscO7YYX",
        "outputId": "58e003f2-8838-4905-e39d-231c9199dd2e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(<Figure size 864x576 with 1 Axes>,\n",
              " <AxesSubplot:xlabel='Regression Models for non-shot based expected match value', ylabel='Mean Squared Error'>)"
            ]
          },
          "execution_count": 314,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# adding all errors into a list to display in bar plot\n",
        "nonshot_training_eva =[mse_lr_nonshot_train, mse_rf_nonshot_train, mse_svm_nonshot_train]\n",
        "nonshot_testing_eva =[mse_lr_nonshot_test, mse_rf_nonshot_test, mse_svm_nonshot_test]\n",
        "nonshot_diff_eva = [genloss_lr_nonshot, genloss_rf_nonshot, genloss_svm_nonshot]\n",
        "\n",
        "# plotting\n",
        "nonshot_plot = barplot(nonshot_training_eva,nonshot_testing_eva,nonshot_diff_eva,'Regression Models for non-shot based expected match value')\n",
        "nonshot_plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4qVBgIr7YYY"
      },
      "source": [
        "LR has the seecond smallest mean squared error but it has a much lower generalisation loss compared to RF. Hence, it was chosen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSxRcz48pRLw"
      },
      "source": [
        "#### Predicting with selected models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdREzbOwpXQo"
      },
      "outputs": [],
      "source": [
        "shots_match = SVM_fit.predict(x_shots_scale) # best model for shots is SVM\n",
        "nonshot_match = lr_nonshot.predict(x_nonshot_scale) # best model for non-shots is LR\n",
        "\n",
        "# inserting features into dataset\n",
        "shots['exp_match'] = shots_match\n",
        "nonshot['exp_match'] = nonshot_match"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s8sk_jF7YYY"
      },
      "source": [
        "Now that we have the expected match value for both shots and non-shot, we generate the overall expected match value by using their weighted average."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DE-IN7aWPPal"
      },
      "outputs": [],
      "source": [
        "# calculating weighted average\n",
        "w1 = 0.8 # weightage of shot based expected match value\n",
        "w2 = 1-w1 # weightage of non-shot based expected match value\n",
        "avg_expmatch = w1*(shots_match) + w2*(nonshot_match)\n",
        "\n",
        "# separating into home and away teams\n",
        "home_expmatch = avg_expmatch[:4723]\n",
        "away_expmatch = avg_expmatch[4723:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-sKgrqE7YYY"
      },
      "source": [
        "Then, we adjust the overall expected match value by adding the probability of penalty scoring multiplied by the total number of penalty attempts, obtaining our final expected match value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p4Qy3tP7YYY"
      },
      "outputs": [],
      "source": [
        "# adjusting expected match value based on penalty attempts\n",
        "# probability of a penalty scoring is 0.76\n",
        "Hpen_att = df_epl['HPA']\n",
        "Apen_att = df_epl['APA']\n",
        "home_expmatch2 = home_expmatch + 0.76*(Hpen_att)\n",
        "away_expmatch2 = away_expmatch + 0.76*(Apen_att)\n",
        "\n",
        "# inserting expected values into dataset\n",
        "df_epl['H_EXP_adj'] = home_expmatch2.tolist()\n",
        "df_epl['A_EXP_adj'] = away_expmatch2.tolist()\n",
        "df_epl['H_EXP'] = home_expmatch.tolist()\n",
        "df_epl['A_EXP'] = away_expmatch.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-pHzA4HqQEk"
      },
      "source": [
        "### Calculation of ELO\n",
        "Now that we have all of the expected match values of both teams for each match, we take the difference between the values to decide how much we change the ELO rating after each match."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJCkqk-YrIsE"
      },
      "source": [
        "#### Defining functions\n",
        "Here, we are preparing functions that will be used to update the ELO rating in certain circumstances:\n",
        "1. Initial ELO rating of all teams is set to 1500\n",
        "2. Update ELO rating after each match\n",
        "3. Update ELO rating between each season\n",
        "4. Update average ELO rating once home/away rating has been changed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxmjRUQxUg6N"
      },
      "outputs": [],
      "source": [
        "# function to give initial elo\n",
        "def initialize_elo(clubnames): ### clubnames to be in data preprocessing\n",
        "    EloHome_list = []\n",
        "    EloAway_list = []\n",
        "    EloAvg_list = []\n",
        "    for club in clubnames:\n",
        "        EloHome_list.append(1500)\n",
        "        EloAway_list.append(1500)\n",
        "        EloAvg_list.append(1500)\n",
        "\n",
        "    return EloHome_list, EloAway_list, EloAvg_list\n",
        "\n",
        "# function to calculate and update elo after each match with difference between both team's expected match value\n",
        "def update_elo_match(df, n, elohomelist, eloawaylist, eloavglist):\n",
        "\n",
        "    w3 = 20 # sensitivity of ELO changes\n",
        "\n",
        "    # storing teams ELO values before each match in seperate variables\n",
        "    elohome1 = elohomelist[df.iloc[n,1]]\n",
        "    eloaway1 = eloawaylist[df.iloc[n,1]]\n",
        "    elohome2 = elohomelist[df.iloc[n,2]]\n",
        "    eloaway2 = eloawaylist[df.iloc[n,2]]\n",
        "\n",
        "    # storing expected match values based on performance during the match in seperate variables\n",
        "    xg1 = df.iloc[n,38]\n",
        "    xg2 = df.iloc[n,39]\n",
        "\n",
        "    if xg1 > xg2: #if home team's expected match value is higher\n",
        "        diff = xg1 - xg2 # take difference between expected match value\n",
        "\n",
        "        if elohome1 > eloaway2: # if home team was expected to win\n",
        "            w4 = (elohome1 - eloaway2)/(elohome1 + eloaway2) # weight to adjust change in ELO based on which team was expected to win\n",
        "            new_elohome1 = elohome1 + (w3 * diff) - w4 # home team ELO is increased by a lesser amount because they were expected to win\n",
        "            new_eloaway2 = eloaway2 - (w3 * diff) + w4 # away team ELO is reduced by a lesser amount beacause they were expected to lose\n",
        "        elif elohome1 < eloaway2: # if home team was expected to lose\n",
        "            w4 = (eloaway2 - elohome1)/(elohome1 + eloaway2)\n",
        "            new_elohome1 = elohome1 + (w3 * diff) + w4\n",
        "            new_eloaway2 = eloaway2 - (w3 * diff) - w4\n",
        "        else:\n",
        "            new_elohome1 = elohome1 + (w3 * diff)\n",
        "            new_eloaway2 = eloaway2 - (w3 * diff)\n",
        "\n",
        "    elif xg1 < xg2: # if home team's expected match value is lower\n",
        "        diff2 = xg2 - xg1 # difference\n",
        "\n",
        "        if eloaway2 > elohome1: # if away team was expected to win\n",
        "            w4 = (eloaway2 - elohome1)/(eloaway2 + elohome1)\n",
        "            new_elohome1 = elohome1 - (w3 * diff2) + w4 # decrease home team's home elo by a lesser amount\n",
        "            new_eloaway2 = eloaway2 + (w3 * diff2) - w4 # increase away team's away elo by a lesser amount\n",
        "        elif eloaway2 < elohome1: # if away team was expected to lose\n",
        "            w4 = (elohome1 - eloaway2)/(eloaway2 + elohome1)\n",
        "            new_elohome1 = elohome1 - (w3 * diff2) - w4\n",
        "            new_eloaway2 = eloaway2 + (w3 * diff2) + w4\n",
        "        else:\n",
        "            new_elohome1 = elohome1 - (w3 * diff2)\n",
        "            new_eloaway2 = eloaway2 + (w3 * diff2)\n",
        "\n",
        "    new_eloavg1 = (new_elohome1 + eloaway1) / 2 # update average elo of home team\n",
        "    new_eloavg2 = (new_eloaway2 + elohome2) / 2 # update average elo of away team\n",
        "\n",
        "    # update new elo ratings into elo_list\n",
        "    elohomelist[df.iloc[n,1]] = new_elohome1 # home team's elo home is updated\n",
        "    eloavglist[df.iloc[n,1]] = new_eloavg1 # home team's avg elo is updated\n",
        "    eloawaylist[df.iloc[n,2]] = new_eloaway2 # away team's elo away is updated\n",
        "    eloavglist[df.iloc[n,2]] = new_eloavg2 # away team's avg elo is updated\n",
        "\n",
        "    return elohomelist, eloawaylist, eloavglist\n",
        "\n",
        "# function to update elo after each season\n",
        "def update_elo_season(elohomelist, eloawaylist):\n",
        "    w5 = 2/3 # weight of previous season ELO rating carried over\n",
        "    for n in range(len(elohomelist)):\n",
        "        elohomelist[n] = (w5*elohomelist[n])+((1-w5)*1500)\n",
        "        eloawaylist[n] = (w5*eloawaylist[n])+((1-w5)*1500)\n",
        "\n",
        "    return elohomelist, eloawaylist\n",
        "\n",
        "# function to update avg elo after home or away elo has been changed\n",
        "def update_avg_elo(elohomelist, eloawaylist, eloavglist):\n",
        "    for n in range(len(EloHome_list)):\n",
        "        eloavglist[n] = (elohomelist[n] + eloawaylist[n]) / 2\n",
        "\n",
        "    return eloavglist\n",
        "\n",
        "# function to check days since last match to judge if it is a new season\n",
        "def cal_days (df,n): # n is the row number\n",
        "    if n == 0:\n",
        "        daysdiff = 0 # first match no days difference\n",
        "    else:\n",
        "        date1 = datetime.strptime(df['Date'][n],'%d-%m-%y') # date for current match\n",
        "        date2 = datetime.strptime(df['Date'][n-1],'%d-%m-%y') # date for previous match\n",
        "        daysdiff = (date1.date() - date2.date()).days # days difference between previous and current match\n",
        "    return daysdiff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v38Fw8wq5vb"
      },
      "source": [
        "#### Updating ELO\n",
        "1. ELO will be updated each match based on difference between expected match values and initial ELO ratings\n",
        "2. ELO will be regulated between each season to ensure it stays within reasonable range\n",
        "3. ELO will be inserted into final dataset to be used for classification model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMwSE4JG7YYY"
      },
      "source": [
        "Preparing dataset to store initial and final ELO ratings for each team."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phMT7V1GVZ8V"
      },
      "outputs": [],
      "source": [
        "# converting clubnames to integers\n",
        "df_epl2 = conv_clubname_to_int(df_epl,clubnames)\n",
        "\n",
        "# initialize elo for all home away and avg elo for all teams\n",
        "EloHome_list, EloAway_list, EloAvg_list = initialize_elo(clubnames)\n",
        "EloAvg_list = update_avg_elo(EloHome_list, EloAway_list, EloAvg_list)\n",
        "\n",
        "# new columns to store ELO ratings for each match\n",
        "df_epl[\"Home Team Elo After\"] = \"\"\n",
        "df_epl[\"Away Team Elo After\"] = \"\"\n",
        "df_epl[\"Home Team Initial Elo\"] = \"\"\n",
        "df_epl[\"Away Team Initial Elo\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9FslcFb7YYY"
      },
      "source": [
        "Before each match, we check if it is a new season and update ELO rating accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZNEOW967YYY"
      },
      "outputs": [],
      "source": [
        "for n in range(df_epl.shape[0]):\n",
        "    # check if it is a new season\n",
        "    daysdiff = cal_days(df_epl,n)\n",
        "    if daysdiff > 30: # matches within a season will usually take place within 30 days\n",
        "        EloHome_list, EloAway_list = update_elo_season(EloHome_list,EloAway_list) # call function to update ELO between seasons\n",
        "        EloAvg_list = update_avg_elo(EloHome_list, EloAway_list, EloAvg_list)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    # update initial elo ratings into table row by row which is the weighted average of average and home/away ELO\n",
        "    w6 = 0.8 # weightage for home/away elo\n",
        "    w7 = 1-w6 # weightage for avg elo\n",
        "    initial_elohome = (w6 * EloHome_list[df_epl2.iloc[n,1]]) + (w7 * EloAvg_list[df_epl2.iloc[n,1]])\n",
        "    initial_eloaway = (w6 * EloAway_list[df_epl2.iloc[n,2]]) + (w7 * EloAvg_list[df_epl2.iloc[n,2]])\n",
        "    df_epl.iloc[n,44] = initial_elohome\n",
        "    df_epl.iloc[n,45] = initial_eloaway\n",
        "\n",
        "    # update elo after each match\n",
        "    EloHome_list, EloAway_list, EloAvg_list = update_elo_match(df_epl2, n, EloHome_list, EloAway_list, EloAvg_list)\n",
        "\n",
        "    # update new elo ratings into table row by row\n",
        "    new_elohome = (w6 * EloHome_list[df_epl2.iloc[n,1]]) + (w7 * EloAvg_list[df_epl2.iloc[n,1]])\n",
        "    new_eloaway = (w6 * EloAway_list[df_epl2.iloc[n,2]]) + (w7 * EloAvg_list[df_epl2.iloc[n,2]])\n",
        "    df_epl.iloc[n,42] = new_elohome\n",
        "    df_epl.iloc[n,43] = new_eloaway"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH8EnbzdtDQ0"
      },
      "source": [
        "## Last N Points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tuCPZLrsJdqE",
        "outputId": "7df87048-b829-4479-8e90-8f0a8ac666ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HomeTeamLastNPoints</th>\n",
              "      <th>AwayTeamLastNPoints</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4718</th>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4719</th>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4720</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4721</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4722</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4723 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      HomeTeamLastNPoints  AwayTeamLastNPoints\n",
              "0                       0                    0\n",
              "1                       0                    0\n",
              "2                       0                    0\n",
              "3                       0                    0\n",
              "4                       0                    0\n",
              "...                   ...                  ...\n",
              "4718                    8                    9\n",
              "4719                   15                    6\n",
              "4720                    4                    5\n",
              "4721                    4                    5\n",
              "4722                    6                    7\n",
              "\n",
              "[4723 rows x 2 columns]"
            ]
          },
          "execution_count": 287,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Last N Points\n",
        "clubnames = []\n",
        "for name in df_epl[\"HomeTeam\"]:\n",
        "    if name not in clubnames:\n",
        "        clubnames.append(name)\n",
        "\n",
        "def create_team_history(df, clubnames):\n",
        "    #initialize the dictionary\n",
        "    team_history_dict = {}\n",
        "    for club in clubnames:\n",
        "        #n = clubnames.index(club)\n",
        "        team_history_dict[club] = [\"0\"]\n",
        "\n",
        "    for index in range(df.shape[0]):\n",
        "        if df.iloc[index,2] == \"H\": #home win\n",
        "            team_history_dict[df.iloc[index,0]].append(\"3\") #3 points to home team\n",
        "            team_history_dict[df.iloc[index,1]].append(\"0\") #0 points to away team\n",
        "\n",
        "        elif df.iloc[index,2] == \"A\": #home win\n",
        "            team_history_dict[df.iloc[index,0]].append(\"0\") #0 points to home team\n",
        "            team_history_dict[df.iloc[index,1]].append(\"3\") #3 points to away team\n",
        "\n",
        "        if df.iloc[index,2] == \"D\": #home win\n",
        "            team_history_dict[df.iloc[index,0]].append(\"1\") #3 points to home team\n",
        "            team_history_dict[df.iloc[index,1]].append(\"1\") #0 points to away team\n",
        "\n",
        "    return team_history_dict # Dictionary of all team's win/loss\n",
        "\n",
        "def last_n_points(n, match_num, team_history, clubname):\n",
        "    last_n_points = 0\n",
        "\n",
        "    if match_num >= n:\n",
        "        for k in range(match_num-n,match_num):\n",
        "            last_n_points = last_n_points +  int(team_history[clubname][k])\n",
        "\n",
        "    elif match_num == 0:\n",
        "        last_n_points = 0\n",
        "\n",
        "    else:\n",
        "        for k in range(0,match_num):\n",
        "            last_n_points = last_n_points +  int(team_history[clubname][match_num])\n",
        "\n",
        "    return last_n_points\n",
        "\n",
        "def populate_last_n_points(n, df,df2, team_history):\n",
        "    club_cumulative_matches = {}\n",
        "\n",
        "    for club in clubnames:\n",
        "        club_cumulative_matches[club] = -1 #trust me bcos i want it to start from zero (see below)\n",
        "\n",
        "    for index in range(df.shape[0]):\n",
        "        home_team = df.iloc[index,0]\n",
        "        away_team = df.iloc[index,1]\n",
        "\n",
        "        club_cumulative_matches[home_team] = club_cumulative_matches[home_team] + 1\n",
        "        club_cumulative_matches[away_team] = club_cumulative_matches[away_team] + 1\n",
        "\n",
        "        home_team_match_num = club_cumulative_matches[home_team]\n",
        "        away_team_match_num = club_cumulative_matches[away_team]\n",
        "\n",
        "\n",
        "        home_last_n_points = last_n_points(n,home_team_match_num, team_history,home_team)\n",
        "        away_last_n_points = last_n_points(n,away_team_match_num, team_history,away_team)\n",
        "        #df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'), index=['x', 'y'])\n",
        "        #df = df.append({'A': i}, ignore_index=True)\n",
        "        df3 = pd.DataFrame([[home_last_n_points,away_last_n_points]])\n",
        "        df2 = df2.append(df3,ignore_index=True)\n",
        "\n",
        "\n",
        "    return df2\n",
        "# Hshots = Hshots.rename(columns={'HSZA':'SZA','HSZB':'SZB','HSZC':'SZC','HST':'SOT',\n",
        "                              #  'FTHG_P':'FTG_P'})\n",
        "\n",
        "df_lastNPoints = pd.DataFrame()\n",
        "#s2 = pd.Series([0,0], index=['HomeTeamLastNPoints','AwayTeamLastNPoints'])\n",
        "#df_lastNPoints = df_lastNPoints.append(s2,ignore_index=True)\n",
        "df_working = df_pred3.drop(['Date'],axis = 1)\n",
        "team_history = create_team_history(df_working, clubnames)\n",
        "df_lastNPoints = populate_last_n_points(5, df_working, df_lastNPoints, team_history)\n",
        "df_lastNPoints.columns.map(type)\n",
        "df_lastNPoints.columns = df_lastNPoints.columns.astype(str)\n",
        "df_lastNPoints = df_lastNPoints.rename(columns={'0':'HomeTeamLastNPoints','1':'AwayTeamLastNPoints'})\n",
        "#df = lastNPoints_df.drop(['AwayTeam','HomeTeam','FTR'],axis = 1)\n",
        "lastNPoints_df_train = df_lastNPoints.iloc[:4723].copy()\n",
        "lastNPoints_df_test = df_lastNPoints.iloc[4723:].copy()\n",
        "lastNPoints_df_train\n",
        "#df_lastNPoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_wmwLYPuGlI"
      },
      "source": [
        "## Spending"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "sghgjI3NJd0N",
        "outputId": "f0056a3d-f8f9-4c17-b857-666ebe4da1a1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HomeEx</th>\n",
              "      <th>HomeNetSpend</th>\n",
              "      <th>AwayEx</th>\n",
              "      <th>AwayNetSpend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.318398</td>\n",
              "      <td>-0.211064</td>\n",
              "      <td>0.120540</td>\n",
              "      <td>0.068558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.090141</td>\n",
              "      <td>0.198865</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.081466</td>\n",
              "      <td>-0.085106</td>\n",
              "      <td>0.302783</td>\n",
              "      <td>-0.198487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.203666</td>\n",
              "      <td>-0.229787</td>\n",
              "      <td>0.096100</td>\n",
              "      <td>0.015792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.158181</td>\n",
              "      <td>0.042931</td>\n",
              "      <td>0.081466</td>\n",
              "      <td>0.303830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4718</th>\n",
              "      <td>0.363258</td>\n",
              "      <td>-0.159732</td>\n",
              "      <td>0.602791</td>\n",
              "      <td>0.199543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4719</th>\n",
              "      <td>0.769928</td>\n",
              "      <td>-0.651248</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4720</th>\n",
              "      <td>0.336353</td>\n",
              "      <td>0.049927</td>\n",
              "      <td>0.158816</td>\n",
              "      <td>0.038179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4721</th>\n",
              "      <td>0.443438</td>\n",
              "      <td>-0.539158</td>\n",
              "      <td>0.260266</td>\n",
              "      <td>0.126774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4722</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.406401</td>\n",
              "      <td>-0.472100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4723 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        HomeEx  HomeNetSpend    AwayEx  AwayNetSpend\n",
              "0     0.318398     -0.211064  0.120540      0.068558\n",
              "1     0.090141      0.198865  1.000000     -1.000000\n",
              "2     0.081466     -0.085106  0.302783     -0.198487\n",
              "3     0.203666     -0.229787  0.096100      0.015792\n",
              "4     0.158181      0.042931  0.081466      0.303830\n",
              "...        ...           ...       ...           ...\n",
              "4718  0.363258     -0.159732  0.602791      0.199543\n",
              "4719  0.769928     -0.651248  0.000000      0.000000\n",
              "4720  0.336353      0.049927  0.158816      0.038179\n",
              "4721  0.443438     -0.539158  0.260266      0.126774\n",
              "4722  1.000000     -1.000000  0.406401     -0.472100\n",
              "\n",
              "[4723 rows x 4 columns]"
            ]
          },
          "execution_count": 214,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Spending\n",
        "#Scrapping for spend data\n",
        "#Transfermarkt webscraping function from https://fcpython.com/blog/introduction-scraping-data-transfermarkt\n",
        "\n",
        "#Webscraping will not work if website knows we are not a browser, so a fake browser is used\n",
        "headers = {'User-Agent':\n",
        "           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
        "#Define function to take the year, and output table of expenses and balance for each season\n",
        "def get_spend(year):\n",
        "    pageTree = requests.get('https://www.transfermarkt.co.uk/premier-league/einnahmenausgaben/wettbewerb/GB1/plus/0?ids=a&sa=&saison_id='+year+'&saison_id_bis='+year+'&nat=&pos=&altersklasse=&w_s=&leihe=false&intern=1', headers=headers)\n",
        "    pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
        "    club = pageSoup.find_all(\"td\", {\"class\": \"hauptlink no-border-links\"})\n",
        "    ex = pageSoup.find_all(\"td\", {\"class\": \"rechts hauptlink redtext\"})\n",
        "    bal = pageSoup.find_all(\"td\", {\"class\": \"rechts hauptlink\"})\n",
        "    rows=[]\n",
        "    #The team names are different on the website, use dictionary to replace each name\n",
        "    team_name_match_dict={'Arsenal FC':'Arsenal',\n",
        "                      'Chelsea FC':'Chelsea',\n",
        "                      'Blackburn Rovers':'Blackburn',\n",
        "                      'Bolton Wanderers':'Bolton',\n",
        "                      'Liverpool FC':'Liverpool',\n",
        "                      'Sunderland AFC':'Sunderland',\n",
        "                      'Fulham FC':'Fulham',\n",
        "                      'Portsmouth FC':'Portsmouth',\n",
        "                      'Everton FC':'Everton',\n",
        "                      'Middlesbrough FC':'Middlesbrough',\n",
        "                      'Burnley FC':'Burnley',\n",
        "                      'Brighton & Hove Albion':'Brighton',\n",
        "                      'Cardiff City':'Cardiff',\n",
        "                      'Huddersfield Town':'Huddersfield',\n",
        "                      'Hull City':'Hull',\n",
        "                      'Leicester City':'Leicester',\n",
        "                      'Watford FC':'Watford',\n",
        "                      'Manchester City':'Man City',\n",
        "                      'Manchester United':'Man United',\n",
        "                      'AFC Bournemouth':'Bournemouth',\n",
        "                      'Southampton FC':'Southampton',\n",
        "                      'Newcastle United':'Newcastle',\n",
        "                      'Norwich City':'Norwich',\n",
        "                      'Queens Park Rangers':'QPR',\n",
        "                      'Stoke City':'Stoke',\n",
        "                      'Swansea City':'Swansea',\n",
        "                      'Tottenham Hotspur':'Tottenham',\n",
        "                      'West Bromwich Albion':'West Brom',\n",
        "                      'West Ham United':'West Ham',\n",
        "                      'Wigan Athletic':'Wigan',\n",
        "                      'Wolverhampton Wanderers':'Wolves'}\n",
        "    #Remove symbols and units, and replace them\n",
        "    for i in range(len(club)):\n",
        "        ex[i]=ex[i].text.replace('Â£','').replace('m','000000').replace('Th.','000').replace('.','')\n",
        "        bal[i]=bal[i].text.replace('Â£','').replace('m','000000').replace('Th.','000').replace('.','')\n",
        "        #One particular club did not spend any money during a season. This changes that from 'null' to zero\n",
        "        if ex[i]=='-':\n",
        "          ex[i]=0\n",
        "        rows.append([club[i].text,ex[i],bal[i]])\n",
        "    spend_df = pd.DataFrame(rows,columns=['Club','Expenses','Balance'])\n",
        "    spend_df['Club']=spend_df['Club'].replace(team_name_match_dict)\n",
        "    spend_df[['Expenses','Balance']]=MaxAbsScaler().fit(spend_df[['Expenses','Balance']]).transform(spend_df[['Expenses','Balance']])\n",
        "    return spend_df\n",
        "\n",
        "#Create dictionary for spending\n",
        "spend_d={}\n",
        "for i in range(2008,2022):\n",
        "    spend_d[\"{0}\".format(i)]=get_spend(str(i))\n",
        "\n",
        "def get_spending():\n",
        "  data = df_pred3\n",
        "  rows=[]\n",
        "  for i in range(len(data)):\n",
        "      row=[0,0,0,0]\n",
        "      #Change date in each row from string to datetime object\n",
        "      try:\n",
        "          t=datetime.strptime(data['Date'][i],'%d-%m-%y')\n",
        "      except ValueError:\n",
        "          t=datetime.strptime(data['Date'][i],'%d-%m-%y')\n",
        "      #To determine which season the current match belongs to, it is observed that the EPL season starts around August and ends around June\n",
        "      #Therefore, if the month is greater than or equal to 8, it is assigned the current year\n",
        "      #If the month is less than or equal to 6, it is assigned the previous year\n",
        "      if t.month>=8:\n",
        "          for j in range(len(spend_d[str(t.year)])):\n",
        "              if spend_d[str(t.year)]['Club'][j]==data['HomeTeam'][i]:\n",
        "                  row[0]=spend_d[str(t.year)]['Expenses'][j]\n",
        "                  row[1]=spend_d[str(t.year)]['Balance'][j]\n",
        "              elif spend_d[str(t.year)]['Club'][j]==data['AwayTeam'][i]:\n",
        "                  row[2]=spend_d[str(t.year)]['Expenses'][j]\n",
        "                  row[3]=spend_d[str(t.year)]['Balance'][j]\n",
        "      elif t.month<=6:\n",
        "          for k in range(len(spend_d[str(t.year-1)])):\n",
        "              if spend_d[str(t.year-1)]['Club'][k]==data['HomeTeam'][i]:\n",
        "                  row[0]=spend_d[str(t.year-1)]['Expenses'][k]\n",
        "                  row[1]=spend_d[str(t.year-1)]['Balance'][k]\n",
        "              elif spend_d[str(t.year-1)]['Club'][k]==data['AwayTeam'][i]:\n",
        "                  row[2]=spend_d[str(t.year-1)]['Expenses'][k]\n",
        "                  row[3]=spend_d[str(t.year-1)]['Balance'][k]\n",
        "      rows.append(row)\n",
        "  spending_df=pd.DataFrame(rows,columns=['HomeEx','HomeNetSpend','AwayEx','AwayNetSpend'])\n",
        "  return spending_df\n",
        "spending_df=get_spending()\n",
        "spending_df_train = spending_df.iloc[:4723]\n",
        "spending_df_test = spending_df.iloc[4723:]\n",
        "spending_df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU2EdCqouJLC"
      },
      "source": [
        "## Fatigue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "Bzel-qwbJd2s",
        "outputId": "c27cd9c9-4226-426a-a52e-ba86857da9a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:726: RuntimeWarning: overflow encountered in exp\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HFati</th>\n",
              "      <th>AFati</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4718</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4719</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4720</th>\n",
              "      <td>0.017986</td>\n",
              "      <td>0.377541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4721</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.377541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4722</th>\n",
              "      <td>0.377541</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4723 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         HFati     AFati\n",
              "0     0.000001  0.000001\n",
              "1     0.000001  0.000001\n",
              "2     0.000001  0.000001\n",
              "3     0.000001  0.000001\n",
              "4     0.000001  0.000001\n",
              "...        ...       ...\n",
              "4718  0.500000  0.500000\n",
              "4719  0.500000  0.500000\n",
              "4720  0.017986  0.377541\n",
              "4721  0.500000  0.377541\n",
              "4722  0.377541  0.500000\n",
              "\n",
              "[4723 rows x 2 columns]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Fatigue\n",
        "def get_fatigue():\n",
        "  data = pd.read_csv('epl-training2.csv')\n",
        "  fatigue_df = pd.DataFrame(30,index=range(len(data)),columns=['HFati','AFati']) #Create initial dataframe with 30 days as values\n",
        "  clubnames = data['HomeTeam'].unique().tolist() #Get club names\n",
        "  for name in clubnames:\n",
        "      a=np.sort(np.append(data[data['HomeTeam']==name].index.values,data[data['AwayTeam']==name].index.values))\n",
        "      rows = []\n",
        "      s = []\n",
        "      #Find all rows with specific club, and convert string to datetime object\n",
        "      for i in a:\n",
        "          t = []\n",
        "          t.append(i)\n",
        "          try:\n",
        "              t.append(datetime.strptime(data['Date'][i],'%d-%m-%y'))\n",
        "          except ValueError:\n",
        "              t.append(datetime.strptime(data['Date'][i],'%d-%m-%y'))\n",
        "          s.append(t)\n",
        "      #Find difference in days between matches\n",
        "      for i in range(len(s)-1):\n",
        "          row = [s[i+1][0],(s[i+1][1].date()-s[i][1].date()).days]\n",
        "          rows.append(row)\n",
        "      f_df = pd.DataFrame(rows,columns=['n','F'])\n",
        "      #Change values in fatigue_df from 30 days to actual number of days between matches\n",
        "      for i in range(len(f_df['n'])):\n",
        "          if data['HomeTeam'][f_df['n'][i]]==name:\n",
        "              fatigue_df['HFati'][f_df['n'][i]]=f_df['F'][i]\n",
        "          elif data['AwayTeam'][f_df['n'][i]]==name:\n",
        "              fatigue_df['AFati'][f_df['n'][i]]=f_df['F'][i]\n",
        "  #Transform number of days to a fatigue index between 0 and 1\n",
        "  fatigue_df['HFati']=1/(1+np.exp(0.5*(fatigue_df['HFati']-3)))\n",
        "  fatigue_df['AFati']=1/(1+np.exp(0.5*(fatigue_df['AFati']-3)))\n",
        "  return fatigue_df\n",
        "fatigue_df=get_fatigue()\n",
        "fatigue_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-wb9LCZuLoi"
      },
      "source": [
        "## Distance Travelled by Away Team"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "g71DcHIhJwyT",
        "outputId": "26d9ec4b-e554-45ab-c4ab-8a8b2bd743d1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Away travel distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4723</th>\n",
              "      <td>85.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4724</th>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4725</th>\n",
              "      <td>244.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4726</th>\n",
              "      <td>46.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4727</th>\n",
              "      <td>156.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4728</th>\n",
              "      <td>215.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4729</th>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4730</th>\n",
              "      <td>205.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4731</th>\n",
              "      <td>267.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4732</th>\n",
              "      <td>145.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Away travel distance\n",
              "4723                  85.4\n",
              "4724                 200.0\n",
              "4725                 244.0\n",
              "4726                  46.1\n",
              "4727                 156.0\n",
              "4728                 215.0\n",
              "4729                   4.5\n",
              "4730                 205.0\n",
              "4731                 267.0\n",
              "4732                 145.0"
            ]
          },
          "execution_count": 281,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Distance Travelled\n",
        "#Distance data taken from Google Maps, shortest distance by car from away team stadium to home team stadium\n",
        "def get_dist():\n",
        "  data = df_pred3\n",
        "  dist = pd.read_csv('dist.csv') #Import distance from each club\n",
        "  rows = []\n",
        "  for i in range(len(data)):\n",
        "      h = data['HomeTeam'][i]\n",
        "      a = data['AwayTeam'][i]\n",
        "      for j in dist[dist['Home']==h].index.values:\n",
        "          if dist['Away'][j] == a:\n",
        "              rows.append(dist['Miles'][j])\n",
        "      for j in dist[dist['Away']==h].index.values:\n",
        "          if dist['Home'][j] == a:\n",
        "              rows.append(dist['Miles'][j])\n",
        "  dist_df = pd.DataFrame(rows,columns=['Away travel distance'])\n",
        "  return dist_df\n",
        "dist_df=get_dist()\n",
        "dist_df_train = dist_df.iloc[:4723]\n",
        "dist_df_test = dist_df.iloc[4723:]\n",
        "dist_df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEtCNF9s7YYZ"
      },
      "source": [
        "Now, we combine all of our features into a new dataset to be used for our classification model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdSbVYv47YYZ",
        "outputId": "15127b2c-57b8-4903-bf62-3ddfb3aa59b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FTR</th>\n",
              "      <th>ExDiff</th>\n",
              "      <th>NetSpendDiff</th>\n",
              "      <th>Away travel distance</th>\n",
              "      <th>FatiDiff</th>\n",
              "      <th>LastNPointsDiff</th>\n",
              "      <th>ELODiff</th>\n",
              "      <th>FoulsDiff</th>\n",
              "      <th>YcardDiff</th>\n",
              "      <th>RcardDiff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>0.197858</td>\n",
              "      <td>-0.279622</td>\n",
              "      <td>89.4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A</td>\n",
              "      <td>-0.909859</td>\n",
              "      <td>1.198865</td>\n",
              "      <td>27.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A</td>\n",
              "      <td>-0.221317</td>\n",
              "      <td>0.113381</td>\n",
              "      <td>147.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>H</td>\n",
              "      <td>0.107566</td>\n",
              "      <td>-0.245579</td>\n",
              "      <td>198.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A</td>\n",
              "      <td>0.076714</td>\n",
              "      <td>-0.260898</td>\n",
              "      <td>208.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4718</th>\n",
              "      <td>A</td>\n",
              "      <td>-0.239533</td>\n",
              "      <td>-0.359276</td>\n",
              "      <td>161.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1</td>\n",
              "      <td>2.4082</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4719</th>\n",
              "      <td>H</td>\n",
              "      <td>0.769928</td>\n",
              "      <td>-0.651248</td>\n",
              "      <td>40.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>874.921</td>\n",
              "      <td>-4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4720</th>\n",
              "      <td>A</td>\n",
              "      <td>0.177536</td>\n",
              "      <td>0.011747</td>\n",
              "      <td>190.0</td>\n",
              "      <td>-0.359554</td>\n",
              "      <td>-1</td>\n",
              "      <td>190.748</td>\n",
              "      <td>-3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4721</th>\n",
              "      <td>D</td>\n",
              "      <td>0.183172</td>\n",
              "      <td>-0.665932</td>\n",
              "      <td>83.5</td>\n",
              "      <td>0.122459</td>\n",
              "      <td>-1</td>\n",
              "      <td>131.178</td>\n",
              "      <td>-4</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4722</th>\n",
              "      <td>H</td>\n",
              "      <td>0.593599</td>\n",
              "      <td>-0.527900</td>\n",
              "      <td>5.4</td>\n",
              "      <td>-0.122459</td>\n",
              "      <td>-1</td>\n",
              "      <td>257.056</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4723 rows Ã— 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     FTR    ExDiff  NetSpendDiff  Away travel distance  FatiDiff  \\\n",
              "0      A  0.197858     -0.279622                  89.4  0.000000   \n",
              "1      A -0.909859      1.198865                  27.2  0.000000   \n",
              "2      A -0.221317      0.113381                 147.0  0.000000   \n",
              "3      H  0.107566     -0.245579                 198.0  0.000000   \n",
              "4      A  0.076714     -0.260898                 208.0  0.000000   \n",
              "...   ..       ...           ...                   ...       ...   \n",
              "4718   A -0.239533     -0.359276                 161.0  0.000000   \n",
              "4719   H  0.769928     -0.651248                  40.3  0.000000   \n",
              "4720   A  0.177536      0.011747                 190.0 -0.359554   \n",
              "4721   D  0.183172     -0.665932                  83.5  0.122459   \n",
              "4722   H  0.593599     -0.527900                   5.4 -0.122459   \n",
              "\n",
              "      LastNPointsDiff  ELODiff  FoulsDiff  YcardDiff  RcardDiff  \n",
              "0                   0        0          1          0          0  \n",
              "1                   0        0          3          1          0  \n",
              "2                   0        0          6          1          0  \n",
              "3                   0        0         -2         -1          0  \n",
              "4                   0        0         -2          0          0  \n",
              "...               ...      ...        ...        ...        ...  \n",
              "4718               -1   2.4082          3          2          0  \n",
              "4719                9  874.921         -4          0          0  \n",
              "4720               -1  190.748         -3          2          0  \n",
              "4721               -1  131.178         -4         -2          0  \n",
              "4722               -1  257.056         -1          2         -1  \n",
              "\n",
              "[4723 rows x 10 columns]"
            ]
          },
          "execution_count": 270,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# copying features from their respective datasets to a new dataframe\n",
        "# to reduce the number of features we take the difference between home and away values for all features except away distance travelled as that only applies to the away team\n",
        "df_ftr = df_epl.join(pd.get_dummies(df_epl['FTR'],prefix='FTR'))\n",
        "df_final = df_ftr[[\"FTR\"]].copy()\n",
        "df_final['ExDiff'] = spending_df_train['HomeEx']-spending_df_train['AwayEx']\n",
        "df_final['NetSpendDiff'] = spending_df_train['HomeNetSpend']-spending_df_train['AwayNetSpend']\n",
        "df_final['Away travel distance'] = dist_df_train[['Away travel distance']].copy()\n",
        "df_final['FatiDiff'] = fatigue_df['HFati']-fatigue_df['AFati']\n",
        "df_final['LastNPointsDiff'] = lastNPoints_df_train[\"HomeTeamLastNPoints\"] - lastNPoints_df_train[\"AwayTeamLastNPoints\"]\n",
        "df_final['ELODiff'] = df_epl[\"Home Team Initial Elo\"] - df_epl[\"Away Team Initial Elo\"]\n",
        "df_final['FoulsDiff'] = df_epl['HF']-df_epl['AF']\n",
        "df_final['YcardDiff']= df_epl['HY']-df_epl['AY']\n",
        "df_final['RcardDiff']=df_epl['HR']-df_epl['AR']\n",
        "df_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3fCgrPV7YYZ"
      },
      "source": [
        "# Feature Selection\n",
        "Now that we have all our features, we can evaluate the strength of correlation between all features and our target value. We will be using a statistical method to choose our features for our final predictive classification model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5CwiOS6UnvZ"
      },
      "outputs": [],
      "source": [
        "# Separating dataset into x and y\n",
        "X,Y = df_final.drop(['FTR'],axis=1), df_final[\"FTR\"].copy()\n",
        "\n",
        "# standardising data\n",
        "scaler = StandardScaler()\n",
        "X_scale = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bd_TRB2V7YYZ",
        "outputId": "c5ed6278-af33-4d6d-b704-04bc86b8a56b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "corr3 = df_final.corr()\n",
        "sb.heatmap(corr3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg_bIgrC7YYZ"
      },
      "source": [
        "Heatmap was generated to evaluate the correlation between the features. No strong correlations was observed. Hence, no changes were made to the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIELwIPV7YYa",
        "outputId": "7e53d270-c6e6-489a-b1b1-24346d897587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MI scores for all variables of X:\n",
            "ExDiff 1.0253407230892182\n",
            "NetSpendDiff 1.0206176221571792\n",
            "ELODiff 0.0879443046056596\n",
            "LastNPointsDiff 0.017948494412272087\n",
            "Away travel distance 0.011818429063986002\n",
            "RcardDiff 0.007425110834361925\n",
            "YcardDiff 0.005092392142549196\n",
            "FoulsDiff 0.0\n",
            "FatiDiff 0.0\n",
            "thresholdMIscore: 0.011818429063986002\n",
            "Number of remaining features: 5\n"
          ]
        }
      ],
      "source": [
        "# labellling discrete features\n",
        "discrete = [0,0,1,0,0,0,0,0,0,0]\n",
        "\n",
        "# calculating scores which represent the correlation between each feature and target value\n",
        "MIscores = mutual_info_classif(X,Y,random_state=1,discrete_features=discrete)\n",
        "thresholdMIscore = np.percentile(MIscores,50) # choose the 5 highest correlated features\n",
        "\n",
        "# display scores more clearly\n",
        "sortedMIscores = sorted(zip(MIscores,list(X)),reverse=True)\n",
        "\n",
        "# show list of scores, removing those that do not meet the threshold\n",
        "print('MI scores for all variables of X:')\n",
        "for score, fname in sortedMIscores:\n",
        "    print(fname,score)\n",
        "    if score < thresholdMIscore:\n",
        "        X = X.drop(fname,axis=1)\n",
        "\n",
        "print('thresholdMIscore:',thresholdMIscore)\n",
        "_,n_features = X.shape\n",
        "print('Number of remaining features:',n_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hNNFP-97YYa"
      },
      "source": [
        "After the feature selection process, the remaining features are: difference in expenses, difference in net spending, difference in ELO rating, difference in last N points and away distance travelled."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqUz0Pv5JEg4"
      },
      "source": [
        "# Classification Models\n",
        "Now, we use all our selected features to build our classification model. The process is the same as how we built our regression model which is:\n",
        "1. Train several models using different algorithms\n",
        "2. Validate models using K-fold cross validation\n",
        "3. Tune hyperparameters of relevant algorithms\n",
        "4. Evaluate and select the best performing model\n",
        "\n",
        "However, different evaluation metrics are used for classification. They are:\n",
        "- Accuracy\n",
        "- F1 score\n",
        "- Precision\n",
        "- Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BZLtnf97YYa"
      },
      "outputs": [],
      "source": [
        "# splitting data to training and testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=42)\n",
        "\n",
        "# standardise\n",
        "X_train_scale = scaler.fit_transform(X_train)\n",
        "X_test_scale = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTKx4QK27YYa"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oU9vrh4KFEF",
        "outputId": "7f2dfdd6-a546-4227-b6c8-b831243928f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of naive bayes for testing set is: 0.4486772486772487\n",
            "accuracy of naive bayes for training set is: 0.45897300158814186\n",
            "difference in accuracy for naive bayes is: 0.010295752910893186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.02      0.55      0.04        11\n",
            "           D       0.00      0.00      0.00         0\n",
            "           H       1.00      0.45      0.62       934\n",
            "\n",
            "    accuracy                           0.45       945\n",
            "   macro avg       0.34      0.33      0.22       945\n",
            "weighted avg       0.99      0.45      0.61       945\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# create a base model\n",
        "nb = GaussianNB()\n",
        "\n",
        "# fit\n",
        "nb.fit(X_train_scale, Y_train)\n",
        "\n",
        "# predict\n",
        "y_nb_train = nb.predict(X_train) #prediction\n",
        "y_nb_test = nb.predict(X_test)\n",
        "\n",
        "# evaluate\n",
        "acc_nb_test = accuracy_score(Y_test,y_nb_test)\n",
        "acc_nb_train = accuracy_score(Y_train,y_nb_train)\n",
        "acc_nb_diff = acc_nb_train - acc_nb_test\n",
        "\n",
        "print('accuracy of naive bayes for testing set is:',acc_nb_test)\n",
        "print('accuracy of naive bayes for training set is:',acc_nb_train)\n",
        "print('difference in accuracy for naive bayes is:',acc_nb_diff)\n",
        "print(metrics.classification_report(y_nb_test,Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxVN_MPR7YYa",
        "outputId": "46ecf1dc-a267-483f-871e-975f49a53026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nested Cross Validation mean test score: 0.5119086162794773\n"
          ]
        }
      ],
      "source": [
        "# cross validation\n",
        "nb_cv = cross_val_score(nb, X=X_train_scale, y=Y_train, cv=5, scoring='accuracy')\n",
        "nb_err = nb_cv.mean()\n",
        "print('Nested Cross Validation mean test score:',nb_err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWOEHx6K7YYa"
      },
      "source": [
        "Since the cross validation mean test score is much larger than our validation test score, we choose to use the cross validation mean test score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfgBAeU57YYa"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbFsXYtLKFbK",
        "outputId": "4e50ede4-d4ea-4671-915c-cd56e6c7ea7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV] class_weight=balanced, penalty=l2, solver=lbfgs .................\n",
            "[CV]  class_weight=balanced, penalty=l2, solver=lbfgs, score=0.635, total=   0.0s\n",
            "[CV] class_weight=balanced, penalty=l2, solver=lbfgs .................\n",
            "[CV]  class_weight=balanced, penalty=l2, solver=lbfgs, score=0.677, total=   0.0s\n",
            "[CV] class_weight=balanced, penalty=l2, solver=lbfgs .................\n",
            "[CV]  class_weight=balanced, penalty=l2, solver=lbfgs, score=0.598, total=   0.0s\n",
            "[CV] class_weight=balanced, penalty=l2, solver=lbfgs .................\n",
            "[CV]  class_weight=balanced, penalty=l2, solver=lbfgs, score=0.612, total=   0.0s\n",
            "[CV] class_weight=balanced, penalty=l2, solver=lbfgs .................\n",
            "[CV]  class_weight=balanced, penalty=l2, solver=lbfgs, score=0.621, total=   0.0s\n",
            "[CV] class_weight=None, penalty=l2, solver=lbfgs .....................\n",
            "[CV]  class_weight=None, penalty=l2, solver=lbfgs, score=0.657, total=   0.0s\n",
            "[CV] class_weight=None, penalty=l2, solver=lbfgs .....................\n",
            "[CV]  class_weight=None, penalty=l2, solver=lbfgs, score=0.661, total=   0.0s\n",
            "[CV] class_weight=None, penalty=l2, solver=lbfgs .....................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV]  class_weight=None, penalty=l2, solver=lbfgs, score=0.648, total=   0.0s\n",
            "[CV] class_weight=None, penalty=l2, solver=lbfgs .....................\n",
            "[CV]  class_weight=None, penalty=l2, solver=lbfgs, score=0.653, total=   0.0s\n",
            "[CV] class_weight=None, penalty=l2, solver=lbfgs .....................\n",
            "[CV]  class_weight=None, penalty=l2, solver=lbfgs, score=0.628, total=   0.0s\n",
            "[CV] C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=balanced, penalty=l1, solver=saga \n",
            "[CV]  C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=balanced, penalty=l1, solver=saga, score=nan, total=   0.0s\n",
            "[CV] C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=balanced, penalty=l1, solver=saga \n",
            "[CV]  C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=balanced, penalty=l1, solver=saga, score=nan, total=   0.0s\n",
            "[CV] C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=balanced, penalty=l1, solver=saga \n",
            "[CV]  C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=balanced, penalty=l1, solver=saga, score=nan, total=   0.0s\n",
            "[CV] C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=balanced, penalty=l1, solver=saga \n",
            "[CV]  C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=balanced, penalty=l1, solver=saga, score=nan, total=   0.0s\n",
            "[CV] C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=balanced, penalty=l1, solver=saga \n",
            "[CV]  C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=balanced, penalty=l1, solver=saga, score=nan, total=   0.0s\n",
            "[CV] C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=None, penalty=l1, solver=saga \n",
            "[CV]  C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=None, penalty=l1, solver=saga, score=nan, total=   0.0s\n",
            "[CV] C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=None, penalty=l1, solver=saga \n",
            "[CV]  C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=None, penalty=l1, solver=saga, score=nan, total=   0.0s\n",
            "[CV] C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=None, penalty=l1, solver=saga \n",
            "[CV]  C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=None, penalty=l1, solver=saga, score=nan, total=   0.0s\n",
            "[CV] C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=None, penalty=l1, solver=saga \n",
            "[CV]  C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=None, penalty=l1, solver=saga, score=nan, total=   0.0s\n",
            "[CV] C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=None, penalty=l1, solver=saga \n",
            "[CV]  C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766D0E370>, class_weight=None, penalty=l1, solver=saga, score=nan, total=   0.0s\n",
            "The best score for LOR is: 0.6495451837835944\n",
            "The best parametesr for LOR are: LogisticRegression()\n",
            "accuracy of lor for training set: 0.6498147167813658\n",
            "accuracy of lor for testing set: 0.6571428571428571\n",
            "diff in accuracy for lor: -0.00732814036149132\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.75      0.72      0.74       301\n",
            "           D       0.14      0.49      0.22        68\n",
            "           H       0.88      0.64      0.74       576\n",
            "\n",
            "    accuracy                           0.66       945\n",
            "   macro avg       0.59      0.62      0.57       945\n",
            "weighted avg       0.79      0.66      0.70       945\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1307, in fit\n",
            "    raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n",
            "ValueError: Penalty term must be positive; got (C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021775E73070>)\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1307, in fit\n",
            "    raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n",
            "ValueError: Penalty term must be positive; got (C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021775F213D0>)\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1307, in fit\n",
            "    raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n",
            "ValueError: Penalty term must be positive; got (C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021766C03250>)\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1307, in fit\n",
            "    raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n",
            "ValueError: Penalty term must be positive; got (C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021775F01A60>)\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1307, in fit\n",
            "    raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n",
            "ValueError: Penalty term must be positive; got (C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021775F01280>)\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1307, in fit\n",
            "    raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n",
            "ValueError: Penalty term must be positive; got (C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021775EEDEE0>)\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1307, in fit\n",
            "    raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n",
            "ValueError: Penalty term must be positive; got (C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021775EED5E0>)\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1307, in fit\n",
            "    raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n",
            "ValueError: Penalty term must be positive; got (C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021775F011C0>)\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1307, in fit\n",
            "    raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n",
            "ValueError: Penalty term must be positive; got (C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021776B23100>)\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Jia Yi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1307, in fit\n",
            "    raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n",
            "ValueError: Penalty term must be positive; got (C=<scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021776B23850>)\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
          ]
        }
      ],
      "source": [
        "# set parameter grid\n",
        "paramgrid_lor = [\n",
        "    {'penalty' : ['l2'],\n",
        "    'solver' : ['lbfgs'],\n",
        "    'class_weight' : ['balanced',None]},\n",
        "    {'penalty' : ['l1'],\n",
        "    'C' : [expon(scale=100)],\n",
        "    'solver' : ['saga'],\n",
        "    'class_weight' : ['balanced',None]}\n",
        "]\n",
        "\n",
        "# instantiate grid search\n",
        "grid_lor = GridSearchCV(LogisticRegression(),paramgrid_lor,cv=5,verbose=3,scoring='accuracy')\n",
        "\n",
        "# fit grid search model\n",
        "grid_lor.fit(X_train_scale, Y_train)\n",
        "\n",
        "# check the best hyperparameters and best test score\n",
        "print('The best score for LOR is:',grid_lor.best_score_)\n",
        "print('The best parametesr for LOR are:',grid_lor.best_estimator_)\n",
        "\n",
        "\n",
        "# build final model with the best hyperparameters\n",
        "lor_model = grid_lor.best_estimator_\n",
        "\n",
        "# fit final model\n",
        "lor_fit = lor_model.fit(X_train_scale,Y_train)\n",
        "\n",
        "# predict\n",
        "y_lor_train = lor_fit.predict(X_train_scale)\n",
        "y_lor_test = lor_fit.predict(X_test_scale)\n",
        "\n",
        "# evaluate\n",
        "acc_lor_train =accuracy_score(Y_train,y_lor_train)\n",
        "acc_lor_test = accuracy_score(Y_test,y_lor_test)\n",
        "acc_lor_diff = acc_lor_train - acc_lor_test\n",
        "\n",
        "print('accuracy of lor for training set:',acc_lor_train)\n",
        "print('accuracy of lor for testing set:',acc_lor_test)\n",
        "print('diff in accuracy for lor:',acc_lor_diff)\n",
        "print(metrics.classification_report(y_lor_test,Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0DNx0F67YYa"
      },
      "source": [
        "## Quadratic Discriminant Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6tk0UDhKFsc",
        "outputId": "09e0914d-6e9e-4549-9e9a-2813c3cdd3c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "[CV] reg_param=0.1 ...................................................\n",
            "[CV] ....................... reg_param=0.1, score=0.656, total=   0.0s\n",
            "[CV] reg_param=0.1 ...................................................\n",
            "[CV] ....................... reg_param=0.1, score=0.665, total=   0.0s\n",
            "[CV] reg_param=0.1 ...................................................\n",
            "[CV] ....................... reg_param=0.1, score=0.638, total=   0.0s\n",
            "[CV] reg_param=0.1 ...................................................\n",
            "[CV] ....................... reg_param=0.1, score=0.620, total=   0.0s\n",
            "[CV] reg_param=0.1 ...................................................\n",
            "[CV] ....................... reg_param=0.1, score=0.630, total=   0.0s\n",
            "[CV] reg_param=0.2 ...................................................\n",
            "[CV] ....................... reg_param=0.2, score=0.659, total=   0.0s\n",
            "[CV] reg_param=0.2 ...................................................\n",
            "[CV] ....................... reg_param=0.2, score=0.680, total=   0.0s\n",
            "[CV] reg_param=0.2 ...................................................\n",
            "[CV] ....................... reg_param=0.2, score=0.643, total=   0.0s\n",
            "[CV] reg_param=0.2 ...................................................\n",
            "[CV] ....................... reg_param=0.2, score=0.628, total=   0.0s\n",
            "[CV] reg_param=0.2 ...................................................\n",
            "[CV] ....................... reg_param=0.2, score=0.624, total=   0.0s\n",
            "[CV] reg_param=0.3 ...................................................\n",
            "[CV] ....................... reg_param=0.3, score=0.665, total=   0.0s\n",
            "[CV] reg_param=0.3 ...................................................\n",
            "[CV] ....................... reg_param=0.3, score=0.672, total=   0.0s\n",
            "[CV] reg_param=0.3 ...................................................\n",
            "[CV] ....................... reg_param=0.3, score=0.649, total=   0.0s\n",
            "[CV] reg_param=0.3 ...................................................\n",
            "[CV] ....................... reg_param=0.3, score=0.632, total=   0.0s\n",
            "[CV] reg_param=0.3 ...................................................\n",
            "[CV] ....................... reg_param=0.3, score=0.623, total=   0.0s\n",
            "[CV] reg_param=0.4 ...................................................\n",
            "[CV] ....................... reg_param=0.4, score=0.649, total=   0.0s\n",
            "[CV] reg_param=0.4 ...................................................\n",
            "[CV] ....................... reg_param=0.4, score=0.677, total=   0.0s\n",
            "[CV] reg_param=0.4 ...................................................\n",
            "[CV] ....................... reg_param=0.4, score=0.649, total=   0.0s\n",
            "[CV] reg_param=0.4 ...................................................\n",
            "[CV] ....................... reg_param=0.4, score=0.633, total=   0.0s\n",
            "[CV] reg_param=0.4 ...................................................\n",
            "[CV] ....................... reg_param=0.4, score=0.624, total=   0.0s\n",
            "[CV] reg_param=0.5 ...................................................\n",
            "[CV] ....................... reg_param=0.5, score=0.649, total=   0.0s\n",
            "[CV] reg_param=0.5 ...................................................\n",
            "[CV] ....................... reg_param=0.5, score=0.677, total=   0.0s\n",
            "[CV] reg_param=0.5 ...................................................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] ....................... reg_param=0.5, score=0.644, total=   0.0s\n",
            "[CV] reg_param=0.5 ...................................................\n",
            "[CV] ....................... reg_param=0.5, score=0.633, total=   0.0s\n",
            "[CV] reg_param=0.5 ...................................................\n",
            "[CV] ....................... reg_param=0.5, score=0.621, total=   0.0s\n",
            "The best score for QDA is: 0.6482154245068152\n",
            "The best parametesr for QDA are: QuadraticDiscriminantAnalysis(reg_param=0.3)\n",
            "accuracy of QDA for training set: 0.6543144520910534\n",
            "accuracy of QDA for testing set: 0.6582010582010582\n",
            "diff in accuracy for QDA: -0.0038866061100047977\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.74      0.74      0.74       292\n",
            "           D       0.24      0.42      0.31       139\n",
            "           H       0.83      0.68      0.75       514\n",
            "\n",
            "    accuracy                           0.66       945\n",
            "   macro avg       0.61      0.61      0.60       945\n",
            "weighted avg       0.72      0.66      0.68       945\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.1s finished\n"
          ]
        }
      ],
      "source": [
        "# set parameter grid\n",
        "paramgrid_qda =[{'reg_param':[0.1,0.2,0.3,0.4,0.5]}]\n",
        "\n",
        "# instantiate grid search\n",
        "grid_qda = GridSearchCV(QDA(),paramgrid_qda,cv=5,verbose=3,scoring='accuracy')\n",
        "\n",
        "# fit grid search model\n",
        "grid_qda.fit(X_train_scale,Y_train)\n",
        "\n",
        "# check the best hyperparameters and best test score\n",
        "print('The best score for QDA is:',grid_qda.best_score_)\n",
        "print('The best parametesr for QDA are:',grid_qda.best_estimator_)\n",
        "\n",
        "# build final model\n",
        "qda_model = grid_qda.best_estimator_\n",
        "\n",
        "# fit final model\n",
        "qda_fit = qda_model.fit(X_train_scale,Y_train)\n",
        "\n",
        "# predict\n",
        "y_qda_train = qda_fit.predict(X_train_scale)\n",
        "y_qda_test = qda_fit.predict(X_test_scale)\n",
        "\n",
        "# evaluate\n",
        "acc_qda_train =accuracy_score(Y_train,y_qda_train)\n",
        "acc_qda_test = accuracy_score(Y_test,y_qda_test)\n",
        "acc_qda_diff = acc_qda_train - acc_qda_test\n",
        "\n",
        "print('accuracy of QDA for training set:',acc_qda_train)\n",
        "print('accuracy of QDA for testing set:',acc_qda_test)\n",
        "print('diff in accuracy for QDA:',acc_qda_diff)\n",
        "print(metrics.classification_report(y_qda_test,Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1ZsNcQB7YYa"
      },
      "source": [
        "## Linear Discriminant Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtSIwA0EKFzD",
        "outputId": "2e8fbead-4242-40f6-95f7-1f6ba59cdee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
            "[CV] solver=svd ......................................................\n",
            "[CV] .......................... solver=svd, score=0.656, total=   0.0s\n",
            "[CV] solver=svd ......................................................\n",
            "[CV] .......................... solver=svd, score=0.663, total=   0.0s\n",
            "[CV] solver=svd ......................................................\n",
            "[CV] .......................... solver=svd, score=0.649, total=   0.0s\n",
            "[CV] solver=svd ......................................................\n",
            "[CV] .......................... solver=svd, score=0.653, total=   0.0s\n",
            "[CV] solver=svd ......................................................\n",
            "[CV] .......................... solver=svd, score=0.629, total=   0.0s\n",
            "[CV] solver=lsqr .....................................................\n",
            "[CV] ......................... solver=lsqr, score=0.656, total=   0.0s\n",
            "[CV] solver=lsqr .....................................................\n",
            "[CV] ......................... solver=lsqr, score=0.663, total=   0.0s\n",
            "[CV] solver=lsqr .....................................................\n",
            "[CV] ......................... solver=lsqr, score=0.649, total=   0.0s\n",
            "[CV] solver=lsqr .....................................................\n",
            "[CV] ......................... solver=lsqr, score=0.653, total=   0.0s\n",
            "[CV] solver=lsqr .....................................................\n",
            "[CV] ......................... solver=lsqr, score=0.629, total=   0.0s\n",
            "[CV] solver=eigen ....................................................\n",
            "[CV] ........................ solver=eigen, score=0.656, total=   0.0s\n",
            "[CV] solver=eigen ....................................................\n",
            "[CV] ........................ solver=eigen, score=0.663, total=   0.0s\n",
            "[CV] solver=eigen ....................................................\n",
            "[CV] ........................ solver=eigen, score=0.649, total=   0.0s\n",
            "[CV] solver=eigen ....................................................\n",
            "[CV] ........................ solver=eigen, score=0.653, total=   0.0s\n",
            "[CV] solver=eigen ....................................................\n",
            "[CV] ........................ solver=eigen, score=0.629, total=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best score for LDA is: 0.6500746347103963\n",
            "The best parametesr for LDA are: LinearDiscriminantAnalysis()\n",
            "accuracy of LDA for training set: 0.6503440974060349\n",
            "accuracy of LDA for testing set: 0.6645502645502646\n",
            "diff in accuracy for LDA: -0.01420616714422962\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.75      0.75      0.75       290\n",
            "           D       0.18      0.51      0.26        83\n",
            "           H       0.88      0.65      0.74       572\n",
            "\n",
            "    accuracy                           0.66       945\n",
            "   macro avg       0.60      0.63      0.59       945\n",
            "weighted avg       0.78      0.66      0.70       945\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# set parameter grid\n",
        "paramgrid_lda =[{'solver':['svd','lsqr','eigen']}]\n",
        "\n",
        "# instantiate grid search\n",
        "grid_lda = GridSearchCV(LDA(),paramgrid_lda,cv=5,verbose=3,scoring='accuracy')\n",
        "\n",
        "# fit grid search model\n",
        "grid_lda.fit(X_train_scale,Y_train)\n",
        "\n",
        "# check the best hyperparameters and best test score\n",
        "print('The best score for LDA is:',grid_lda.best_score_)\n",
        "print('The best parametesr for LDA are:',grid_lda.best_estimator_)\n",
        "\n",
        "# build final model\n",
        "lda_model = grid_lda.best_estimator_\n",
        "\n",
        "# fit final model\n",
        "lda_fit = lda_model.fit(X_train_scale,Y_train)\n",
        "\n",
        "# predict\n",
        "y_lda_train = lda_fit.predict(X_train_scale)\n",
        "y_lda_test = lda_fit.predict(X_test_scale)\n",
        "\n",
        "# evaluate\n",
        "acc_lda_train =accuracy_score(Y_train,y_lda_train)\n",
        "acc_lda_test = accuracy_score(Y_test,y_lda_test)\n",
        "acc_lda_diff = acc_lda_train - acc_lda_test\n",
        "\n",
        "print('accuracy of LDA for training set:',acc_lda_train)\n",
        "print('accuracy of LDA for testing set:',acc_lda_test)\n",
        "print('diff in accuracy for LDA:',acc_lda_diff)\n",
        "print(metrics.classification_report(y_lda_test,Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H88mZFEl7YYa"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSbNiHpQc_HZ",
        "outputId": "810f387c-735e-40ab-f795-e5be7984f6ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    9.8s\n",
            "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   52.5s\n",
            "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed:  6.5min\n",
            "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  9.5min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best score for RFC is: 0.6466351308735414\n",
            "The best parameters for RFC are: RandomForestClassifier(max_depth=110, max_features=2, min_samples_leaf=5,\n",
            "                       min_samples_split=12, n_estimators=300)\n",
            "accuracy of rf for training set is:  0.8464796188459502\n",
            "accuracy of rf for testing set is:  0.6433862433862434\n",
            "accuracy difference for rf is:  0.20309337545970685\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.71      0.76      0.73       271\n",
            "           D       0.26      0.40      0.31       151\n",
            "           H       0.82      0.65      0.73       523\n",
            "\n",
            "    accuracy                           0.64       945\n",
            "   macro avg       0.59      0.60      0.59       945\n",
            "weighted avg       0.70      0.64      0.66       945\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# set parameter grid\n",
        "paramgrid_RF = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [90, 100, 110],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [200, 300, 1000]\n",
        "}\n",
        "\n",
        "# Create a base model\n",
        "rfc = RandomForestClassifier()\n",
        "\n",
        "# Instantiate the grid search model\n",
        "grid_rfc = GridSearchCV(estimator = rfc, param_grid = RF_paramgrid,\n",
        "                          cv = 5, n_jobs = -1, verbose = 2, scoring='accuracy')\n",
        "# Fit grid search model\n",
        "grid_rfc.fit(X_train_scale, Y_train)\n",
        "\n",
        "# check the best hyperparameters and best test scores\n",
        "print('The best score for RFC is:',grid_rfc.best_score_)\n",
        "print('The best parameters for RFC are:',grid_rfc.best_estimator_)\n",
        "\n",
        "# build final model\n",
        "rfc_model = grid_rfc.best_estimator_\n",
        "\n",
        "# fit final model\n",
        "rfc_fit = rfc_model.fit(X_train_scale,Y_train)\n",
        "\n",
        "# predict\n",
        "y_rfc_test = rfc_fit.predict(X_test_scale)\n",
        "y_rfc_train = rfc_fit.predict(X_train_scale)\n",
        "\n",
        "# evaluate\n",
        "acc_rfc_test = accuracy_score(Y_test,y_rfc_test)\n",
        "acc_rfc_train = accuracy_score(Y_train,y_rfc_train)\n",
        "acc_rfc_diff = acc_rfc_train - acc_rfc_test\n",
        "\n",
        "print('accuracy of rf for training set is: ',acc_rfc_train)\n",
        "print('accuracy of rf for testing set is: ',acc_rfc_test)\n",
        "print('accuracy difference for rf is: ',acc_rfc_diff)\n",
        "print(metrics.classification_report(y_rfc_test,Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbpqBNz47YYa"
      },
      "source": [
        "## Model Evaluation and Selection\n",
        "Now, we compare the performance of all our models based on accuracy and select the best performing one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNsqTqxqtd-c",
        "outputId": "dd04d0e7-6296-4ca0-e205-82c9e07c314e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(<Figure size 864x576 with 1 Axes>,\n",
              " <AxesSubplot:xlabel='Classification Models', ylabel='Accuracy'>)"
            ]
          },
          "execution_count": 320,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# function to produce a barplot visualising the training, testing and generalisation loss to aid our decision making\n",
        "def barplot(training, testing, diff,classes):\n",
        "    #width of bar\n",
        "    barwidth =  0.25\n",
        "    fig = plt.subplots(figsize = (12,8))\n",
        "\n",
        "    # position of bar on x axis\n",
        "    br1 = np.arange(len(training))\n",
        "    br2 = [x + barwidth for x in br1]\n",
        "    br3 = [x + barwidth for x in br2]\n",
        "\n",
        "    # make the plot\n",
        "    plt.bar(br1, training, color ='r', width = barwidth, edgecolor='grey',label='training')\n",
        "    plt.bar(br2, testing, color ='g', width = barwidth, edgecolor='grey', label ='testing')\n",
        "    plt.bar(br3, diff, color ='b', width = barwidth, edgecolor ='grey',label ='loss')\n",
        "\n",
        "    # labelling\n",
        "    plt.xticks([r + barwidth for r in range(len(training))],['NB','LOR','QDA','LDA','RF'])\n",
        "    plt.legend()\n",
        "    plt.xlabel(classes)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()\n",
        "\n",
        "    return fig\n",
        "\n",
        "# inserting all accuracy values into list to be displayed on barplot\n",
        "training_eva = [acc_nb_train, acc_lor_train, acc_qda_train,acc_lda_train,acc_rfc_train]\n",
        "testing_eva = [acc_nb_test, acc_lor_test, acc_qda_test,acc_lda_test,acc_rfc_test]\n",
        "diff_eva = [acc_nb_diff, acc_lor_diff, acc_qda_diff,acc_lda_diff,acc_rfc_diff]\n",
        "\n",
        "# plotting\n",
        "plot = barplot(training_eva,testing_eva,diff_eva, 'Classification Models')\n",
        "plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVBj_-197YYc"
      },
      "source": [
        "RF is eliminated due to its high generalisation loss. Among the others, LDA has the best accuracies. Hence, it is chosen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZBzeDMKteZ9",
        "outputId": "6191d257-f79b-4e86-adb7-5e0b480057d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.45897300158814186, 0.6498147167813658, 0.6543144520910534, 0.6503440974060349, 0.8464796188459502]\n",
            "[0.4486772486772487, 0.6571428571428571, 0.6582010582010582, 0.6645502645502646, 0.6433862433862434]\n"
          ]
        }
      ],
      "source": [
        "# double checking the accuracy values\n",
        "print(training_eva)\n",
        "print(testing_eva)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRDeh8kC7YYc"
      },
      "source": [
        "# Final Prediction\n",
        "Finally, we have chosen our best performing classification model and we can now use it to make predictions for our final test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61wc9DLk7YYc"
      },
      "outputs": [],
      "source": [
        "# prepare dataset by inserting columns for features\n",
        "df_predict = pd.read_csv('epl-test.csv')\n",
        "df_teamnames = df_predict.copy()\n",
        "df_teamnames = conv_clubname_to_int(df_teamnames,clubnames)\n",
        "df_predict['EloDiff'] = \"\"\n",
        "df_predict['LastNPoints'] = \"\"\n",
        "df_predict['Ex'] = \"\"\n",
        "df_predict['NetSpend'] = \"\"\n",
        "df_predict['Distance Travelled by Away Team'] = \"\"\n",
        "\n",
        "# inserting all features into their respective columns\n",
        "for n in range(len(df_predict)):\n",
        "    w6 = 0.8 # weightage for home/away elo\n",
        "    w7 = 1-w6 # weightage for avg elo\n",
        "    initial_elohome = (w6 * EloHome_list[df_teamnames.iloc[n,1]]) + (w7 * EloAvg_list[df_teamnames.iloc[n,1]])\n",
        "    initial_eloaway = (w6 * EloAway_list[df_teamnames.iloc[n,2]]) + (w7 * EloAvg_list[df_teamnames.iloc[n,2]])\n",
        "    elodiff = initial_elohome - initial_eloaway\n",
        "    df_predict.iloc[n,3] = elodiff\n",
        "    lastNPoints = lastNPoints_df_test.iloc[n,0] - lastNPoints_df_test.iloc[n,1]\n",
        "    Ex = spending_df_test.iloc[n,0]-spending_df_test.iloc[n,2]\n",
        "    Spending = spending_df_test.iloc[n,1]-spending_df_test.iloc[n,3]\n",
        "    Dist = dist_df_test.iloc[n,0]\n",
        "    df_predict.iloc[n,4] = lastNPoints\n",
        "    df_predict.iloc[n,5] = Ex\n",
        "    df_predict.iloc[n,6] = Spending\n",
        "    df_predict.iloc[n,7] = Dist\n",
        "\n",
        "df_predict\n",
        "\n",
        "# drop date, home and away teams from our feature dataset as they should not affect the output\n",
        "x_predict = df_predict.drop(['Date','HomeTeam','AwayTeam'],axis = 1)\n",
        "\n",
        "# standardise\n",
        "x_predict_scale = scaler.fit_transform(x_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AN-Q8J877YYc",
        "outputId": "e394fc42-34dc-4846-a71d-a764298b9b8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted outcomes:  ['A' 'H' 'H' 'A' 'H' 'H' 'A' 'H' 'H' 'A']\n",
            "confidence level of predicted outcomes:  [[0.726 0.18  0.095]\n",
            " [0.002 0.194 0.803]\n",
            " [0.003 0.191 0.806]\n",
            " [0.449 0.336 0.216]\n",
            " [0.291 0.35  0.359]\n",
            " [0.005 0.194 0.801]\n",
            " [0.986 0.012 0.002]\n",
            " [0.033 0.286 0.681]\n",
            " [0.052 0.278 0.67 ]\n",
            " [0.601 0.236 0.162]]\n"
          ]
        }
      ],
      "source": [
        "# perform final prediction with the chosen LDA model\n",
        "y_predict = lda_fit.predict(x_predict_scale)\n",
        "y_prob = lda_fit.predict_proba(x_predict_scale)\n",
        "print('predicted outcomes: ',y_predict)\n",
        "print('confidence level of predicted outcomes: ',y_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23Aa5fQW7YYc",
        "outputId": "f477acbd-eeec-48e1-fc80-c3bf4c05c3b4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>AwayTeam</th>\n",
              "      <th>FTR</th>\n",
              "      <th>Probability of H</th>\n",
              "      <th>Probability of D</th>\n",
              "      <th>Probability of A</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15-01-22</th>\n",
              "      <td>Aston Villa</td>\n",
              "      <td>Man United</td>\n",
              "      <td>A</td>\n",
              "      <td>0.094587</td>\n",
              "      <td>0.179893</td>\n",
              "      <td>0.725520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15-01-22</th>\n",
              "      <td>West Ham</td>\n",
              "      <td>Leeds</td>\n",
              "      <td>H</td>\n",
              "      <td>0.803488</td>\n",
              "      <td>0.194201</td>\n",
              "      <td>0.002312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15-01-22</th>\n",
              "      <td>Norwich</td>\n",
              "      <td>Everton</td>\n",
              "      <td>H</td>\n",
              "      <td>0.805931</td>\n",
              "      <td>0.190682</td>\n",
              "      <td>0.003387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15-01-22</th>\n",
              "      <td>Brighton</td>\n",
              "      <td>Crystal Palace</td>\n",
              "      <td>A</td>\n",
              "      <td>0.215703</td>\n",
              "      <td>0.335643</td>\n",
              "      <td>0.448654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15-01-22</th>\n",
              "      <td>Wolves</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>H</td>\n",
              "      <td>0.358869</td>\n",
              "      <td>0.350272</td>\n",
              "      <td>0.290859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15-01-22</th>\n",
              "      <td>Liverpool</td>\n",
              "      <td>Brentford</td>\n",
              "      <td>H</td>\n",
              "      <td>0.800754</td>\n",
              "      <td>0.193959</td>\n",
              "      <td>0.005287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15-01-22</th>\n",
              "      <td>Tottenham</td>\n",
              "      <td>Arsenal</td>\n",
              "      <td>A</td>\n",
              "      <td>0.001936</td>\n",
              "      <td>0.012074</td>\n",
              "      <td>0.985990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15-01-22</th>\n",
              "      <td>Man City</td>\n",
              "      <td>Chelsea</td>\n",
              "      <td>H</td>\n",
              "      <td>0.681126</td>\n",
              "      <td>0.286167</td>\n",
              "      <td>0.032706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15-01-22</th>\n",
              "      <td>Newcastle</td>\n",
              "      <td>Watford</td>\n",
              "      <td>H</td>\n",
              "      <td>0.670242</td>\n",
              "      <td>0.278092</td>\n",
              "      <td>0.051666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15-01-22</th>\n",
              "      <td>Burnley</td>\n",
              "      <td>Leicester</td>\n",
              "      <td>A</td>\n",
              "      <td>0.162456</td>\n",
              "      <td>0.236062</td>\n",
              "      <td>0.601482</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             HomeTeam        AwayTeam FTR  Probability of H  Probability of D  \\\n",
              "Date                                                                            \n",
              "15-01-22  Aston Villa      Man United   A          0.094587          0.179893   \n",
              "15-01-22     West Ham           Leeds   H          0.803488          0.194201   \n",
              "15-01-22      Norwich         Everton   H          0.805931          0.190682   \n",
              "15-01-22     Brighton  Crystal Palace   A          0.215703          0.335643   \n",
              "15-01-22       Wolves     Southampton   H          0.358869          0.350272   \n",
              "15-01-22    Liverpool       Brentford   H          0.800754          0.193959   \n",
              "15-01-22    Tottenham         Arsenal   A          0.001936          0.012074   \n",
              "15-01-22     Man City         Chelsea   H          0.681126          0.286167   \n",
              "15-01-22    Newcastle         Watford   H          0.670242          0.278092   \n",
              "15-01-22      Burnley       Leicester   A          0.162456          0.236062   \n",
              "\n",
              "          Probability of A  \n",
              "Date                        \n",
              "15-01-22          0.725520  \n",
              "15-01-22          0.002312  \n",
              "15-01-22          0.003387  \n",
              "15-01-22          0.448654  \n",
              "15-01-22          0.290859  \n",
              "15-01-22          0.005287  \n",
              "15-01-22          0.985990  \n",
              "15-01-22          0.032706  \n",
              "15-01-22          0.051666  \n",
              "15-01-22          0.601482  "
            ]
          },
          "execution_count": 324,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# present predictions in a table with date, home and away teams\n",
        "Submission_results=pd.read_csv('epl-test.csv',index_col=0, encoding='ISO-8859-1')\n",
        "Submission_results['FTR'] = y_predict\n",
        "Submission_results['Probability of H'] = y_prob[:,2]\n",
        "Submission_results['Probability of D'] = y_prob[:,1]\n",
        "Submission_results['Probability of A'] = y_prob[:,0]\n",
        "Submission_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krLueNT57YYc"
      },
      "outputs": [],
      "source": [
        "# export results to csv file\n",
        "Submission_results.to_csv (r'Submission_results.csv', index = True, header=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}